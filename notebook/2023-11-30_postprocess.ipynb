{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "879dfc44-6f99-43c1-adfa-0f54e3c279cb",
   "metadata": {},
   "source": [
    "\n",
    "1. 2段目で1minごとの予測モデルを作る\n",
    "    - 15分周期とかの情報を入れてあげれば分布の偏りも含めてモデルが学習してくれそう？\n",
    "2. 後処理\n",
    "    1. （必要があれば予測値のキャリブレーション）\n",
    "    2. 以下を繰り返す\n",
    "        1. metric に合わせて N分30秒のように表現できる１分おきの地点での期待値のようなスコアを予測値から求める\n",
    "            - 1, 3, 5, 7.5, 10, 12.5, 15, 20, 25, 30 分以内の予測に対して 10,9,8,...1 と重みがつく\n",
    "            - ２回目以降は差分計算で定数時間で求まる\n",
    "        2. スコアが最も高いものをピックアップしてeventを作る(その地点を提出用eventとする)\n",
    "        3. 作ったeventにマッチする可能性のある予測確率を割り引く\n",
    "        \n",
    "      \n",
    "さっきは1分ごとで簡略化して説明したけど、ほんとは tolerance 7.5min とかのために30秒ごとで計算したほうがいい (N分30秒じゃなくて、N分15秒かN分45秒で提出したい)\n",
    "もしくは、1分ごとで最適イベントを作ったあとに、7.5 min と 12.5min の範囲で、15秒ずらしたときに新しくマッチするイベントを見て、よいほうを選ぶか  \n",
    "        \n",
    "1回目の提出が tolerance 36 以内でマッチするイベントに関しては、他の提出がそれに tolerance 36 以内でマッチする確率が0になると考える。\n",
    "つまり、1回目の提出の tolerance 12 以内のやつは、他の提出が 12 以内でマッチする確率が0になる。 (マッチ上書きしても意味ない)\n",
    "1回目の提出の tolerance 36 以内のやつは、他の提出が 36 以内でマッチする確率が0になる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6217bfe2-12d5-4798-be9f-cb8ce5b3593d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b44faf-74a8-494d-b766-e1ada62e4021",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import os\n",
    "from hydra import initialize, compose\n",
    "\n",
    "with initialize(config_path=\"../run/conf\", version_base=None):\n",
    "    cfg = compose(\"cv_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eedb94dd-4f72-4b61-a160-a5f0f6e5f09d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from src.utils.metrics import event_detection_ap\n",
    "from src.utils.periodicity import get_periodicity_dict\n",
    "from src.utils.common import trace\n",
    "from src.utils.post_process import make_submission\n",
    "\n",
    "periodicity_dict = get_periodicity_dict(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a5209009-bcaa-4c96-a816-530bfd4855c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = pl.read_parquet(Path(cfg.dir.data_dir) / \"train_series.parquet\")\n",
    "train_df = train_df.with_columns(\n",
    "            pl.col(\"timestamp\").str.to_datetime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f19a0d7d-1b1e-443c-9db3-0ec38149d9c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "event_df = pl.read_csv(Path(cfg.dir.data_dir) / \"train_events.csv\").drop_nulls()\n",
    "event_df = event_df.with_columns(\n",
    "    pl.col(\"timestamp\").str.to_datetime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "18e2c378-dddd-43e4-a983-7d6eed8fe8f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_df = pl.read_parquet(\"156_gru_transformer_residual.parquet\")\n",
    "pred_all_df = pl.concat([train_df, pred_df], how=\"horizontal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "677e22a3-c335-4e16-8685-97554a8d61f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>series_id</th><th>step</th><th>timestamp</th><th>anglez</th><th>enmo</th><th>row_id</th><th>prediction_onset</th><th>prediction_wakeup</th></tr><tr><td>str</td><td>u32</td><td>datetime[μs, UTC]</td><td>f32</td><td>f32</td><td>f64</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>&quot;038441c925bb&quot;</td><td>0</td><td>2018-08-14 19:30:00 UTC</td><td>2.6367</td><td>0.0217</td><td>0.0</td><td>6.2617e-13</td><td>0.000028</td></tr><tr><td>&quot;038441c925bb&quot;</td><td>1</td><td>2018-08-14 19:30:05 UTC</td><td>2.6368</td><td>0.0215</td><td>1.0</td><td>9.6546e-13</td><td>0.000034</td></tr><tr><td>&quot;038441c925bb&quot;</td><td>2</td><td>2018-08-14 19:30:10 UTC</td><td>2.637</td><td>0.0216</td><td>2.0</td><td>1.1043e-12</td><td>0.000034</td></tr><tr><td>&quot;038441c925bb&quot;</td><td>3</td><td>2018-08-14 19:30:15 UTC</td><td>2.6368</td><td>0.0213</td><td>3.0</td><td>7.2700e-13</td><td>0.000034</td></tr><tr><td>&quot;038441c925bb&quot;</td><td>4</td><td>2018-08-14 19:30:20 UTC</td><td>2.6368</td><td>0.0215</td><td>4.0</td><td>7.1623e-13</td><td>0.000032</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 8)\n",
       "┌──────────────┬──────┬────────────────┬────────┬────────┬────────┬────────────────┬───────────────┐\n",
       "│ series_id    ┆ step ┆ timestamp      ┆ anglez ┆ enmo   ┆ row_id ┆ prediction_ons ┆ prediction_wa │\n",
       "│ ---          ┆ ---  ┆ ---            ┆ ---    ┆ ---    ┆ ---    ┆ et             ┆ keup          │\n",
       "│ str          ┆ u32  ┆ datetime[μs,   ┆ f32    ┆ f32    ┆ f64    ┆ ---            ┆ ---           │\n",
       "│              ┆      ┆ UTC]           ┆        ┆        ┆        ┆ f32            ┆ f32           │\n",
       "╞══════════════╪══════╪════════════════╪════════╪════════╪════════╪════════════════╪═══════════════╡\n",
       "│ 038441c925bb ┆ 0    ┆ 2018-08-14     ┆ 2.6367 ┆ 0.0217 ┆ 0.0    ┆ 6.2617e-13     ┆ 0.000028      │\n",
       "│              ┆      ┆ 19:30:00 UTC   ┆        ┆        ┆        ┆                ┆               │\n",
       "│ 038441c925bb ┆ 1    ┆ 2018-08-14     ┆ 2.6368 ┆ 0.0215 ┆ 1.0    ┆ 9.6546e-13     ┆ 0.000034      │\n",
       "│              ┆      ┆ 19:30:05 UTC   ┆        ┆        ┆        ┆                ┆               │\n",
       "│ 038441c925bb ┆ 2    ┆ 2018-08-14     ┆ 2.637  ┆ 0.0216 ┆ 2.0    ┆ 1.1043e-12     ┆ 0.000034      │\n",
       "│              ┆      ┆ 19:30:10 UTC   ┆        ┆        ┆        ┆                ┆               │\n",
       "│ 038441c925bb ┆ 3    ┆ 2018-08-14     ┆ 2.6368 ┆ 0.0213 ┆ 3.0    ┆ 7.2700e-13     ┆ 0.000034      │\n",
       "│              ┆      ┆ 19:30:15 UTC   ┆        ┆        ┆        ┆                ┆               │\n",
       "│ 038441c925bb ┆ 4    ┆ 2018-08-14     ┆ 2.6368 ┆ 0.0215 ┆ 4.0    ┆ 7.1623e-13     ┆ 0.000032      │\n",
       "│              ┆      ┆ 19:30:20 UTC   ┆        ┆        ┆        ┆                ┆               │\n",
       "└──────────────┴──────┴────────────────┴────────┴────────┴────────┴────────────────┴───────────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_all_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad560e35-da1b-48bf-a8ec-8de7f262ca1f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m pred_df \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mpl\u001b[49m\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./pred_onset.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;241m.\u001b[39mrename({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstacking_prediction_onset\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;241m.\u001b[39mjoin(\n\u001b[1;32m      6\u001b[0m         pl\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./pred_wakeup.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m         \u001b[38;5;241m.\u001b[39mrename({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel_pred\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstacking_prediction_wakeup\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;241m.\u001b[39mdrop(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m      9\u001b[0m         on\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseries_id\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     10\u001b[0m         how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mleft\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     11\u001b[0m     )\n\u001b[1;32m     12\u001b[0m )\n\u001b[1;32m     13\u001b[0m pred_df \u001b[38;5;241m=\u001b[39m pred_df\u001b[38;5;241m.\u001b[39mwith_columns(\n\u001b[1;32m     14\u001b[0m     ((pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;241m-\u001b[39m pl\u001b[38;5;241m.\u001b[39mcol(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstep\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshift(\u001b[38;5;241m1\u001b[39m)) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mchunk_id\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pl' is not defined"
     ]
    }
   ],
   "source": [
    "pred_df = (\n",
    "    pl.read_parquet(\"./pred_onset.parquet\")\n",
    "    .rename({\"label_pred\": \"stacking_prediction_onset\"})\n",
    "    .drop(\"label\")\n",
    "    .join(\n",
    "        pl.read_parquet(\"./pred_wakeup.parquet\")\n",
    "        .rename({\"label_pred\": \"stacking_prediction_wakeup\"})\n",
    "        .drop(\"label\"),\n",
    "        on=[\"series_id\", \"step\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    ")\n",
    "pred_df = pred_df.with_columns(\n",
    "    ((pl.col(\"step\") - pl.col(\"step\").shift(1)) != 12)\n",
    "    .cast(int)\n",
    "    .cumsum()\n",
    "    .over(\"series_id\")\n",
    "    .fill_null(0)\n",
    "    .alias(\"chunk_id\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c79b8347-8bc1-4e2d-9ea7-d5bdb21b96a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fceb43f1-afbf-4a55-98fc-6707044dab5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>series_id</th><th>step</th><th>timestamp</th><th>anglez</th><th>enmo</th><th>row_id</th><th>prediction_onset</th><th>prediction_wakeup</th></tr><tr><td>str</td><td>u32</td><td>datetime[μs, UTC]</td><td>f32</td><td>f32</td><td>f64</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>&quot;fe90110788d2&quot;</td><td>0</td><td>2017-08-04 21:30:00 UTC</td><td>-27.707001</td><td>0.0298</td><td>1.2735396e8</td><td>7.6921e-12</td><td>0.000122</td></tr><tr><td>&quot;fe90110788d2&quot;</td><td>1</td><td>2017-08-04 21:30:05 UTC</td><td>-33.8675</td><td>0.0488</td><td>1.27353961e8</td><td>8.7983e-12</td><td>0.000133</td></tr><tr><td>&quot;fe90110788d2&quot;</td><td>2</td><td>2017-08-04 21:30:10 UTC</td><td>-15.475</td><td>0.1077</td><td>1.27353962e8</td><td>7.8078e-12</td><td>0.000125</td></tr><tr><td>&quot;fe90110788d2&quot;</td><td>3</td><td>2017-08-04 21:30:15 UTC</td><td>-73.656197</td><td>0.053</td><td>1.27353963e8</td><td>5.2174e-12</td><td>0.000128</td></tr><tr><td>&quot;fe90110788d2&quot;</td><td>4</td><td>2017-08-04 21:30:20 UTC</td><td>-53.152901</td><td>0.0601</td><td>1.27353964e8</td><td>3.7010e-12</td><td>0.00011</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 8)\n",
       "┌─────────────┬──────┬─────────────┬────────────┬────────┬─────────────┬─────────────┬─────────────┐\n",
       "│ series_id   ┆ step ┆ timestamp   ┆ anglez     ┆ enmo   ┆ row_id      ┆ prediction_ ┆ prediction_ │\n",
       "│ ---         ┆ ---  ┆ ---         ┆ ---        ┆ ---    ┆ ---         ┆ onset       ┆ wakeup      │\n",
       "│ str         ┆ u32  ┆ datetime[μs ┆ f32        ┆ f32    ┆ f64         ┆ ---         ┆ ---         │\n",
       "│             ┆      ┆ , UTC]      ┆            ┆        ┆             ┆ f32         ┆ f32         │\n",
       "╞═════════════╪══════╪═════════════╪════════════╪════════╪═════════════╪═════════════╪═════════════╡\n",
       "│ fe90110788d ┆ 0    ┆ 2017-08-04  ┆ -27.707001 ┆ 0.0298 ┆ 1.2735396e8 ┆ 7.6921e-12  ┆ 0.000122    │\n",
       "│ 2           ┆      ┆ 21:30:00    ┆            ┆        ┆             ┆             ┆             │\n",
       "│             ┆      ┆ UTC         ┆            ┆        ┆             ┆             ┆             │\n",
       "│ fe90110788d ┆ 1    ┆ 2017-08-04  ┆ -33.8675   ┆ 0.0488 ┆ 1.27353961e ┆ 8.7983e-12  ┆ 0.000133    │\n",
       "│ 2           ┆      ┆ 21:30:05    ┆            ┆        ┆ 8           ┆             ┆             │\n",
       "│             ┆      ┆ UTC         ┆            ┆        ┆             ┆             ┆             │\n",
       "│ fe90110788d ┆ 2    ┆ 2017-08-04  ┆ -15.475    ┆ 0.1077 ┆ 1.27353962e ┆ 7.8078e-12  ┆ 0.000125    │\n",
       "│ 2           ┆      ┆ 21:30:10    ┆            ┆        ┆ 8           ┆             ┆             │\n",
       "│             ┆      ┆ UTC         ┆            ┆        ┆             ┆             ┆             │\n",
       "│ fe90110788d ┆ 3    ┆ 2017-08-04  ┆ -73.656197 ┆ 0.053  ┆ 1.27353963e ┆ 5.2174e-12  ┆ 0.000128    │\n",
       "│ 2           ┆      ┆ 21:30:15    ┆            ┆        ┆ 8           ┆             ┆             │\n",
       "│             ┆      ┆ UTC         ┆            ┆        ┆             ┆             ┆             │\n",
       "│ fe90110788d ┆ 4    ┆ 2017-08-04  ┆ -53.152901 ┆ 0.0601 ┆ 1.27353964e ┆ 3.7010e-12  ┆ 0.00011     │\n",
       "│ 2           ┆      ┆ 21:30:20    ┆            ┆        ┆ 8           ┆             ┆             │\n",
       "│             ┆      ┆ UTC         ┆            ┆        ┆             ┆             ┆             │\n",
       "└─────────────┴──────┴─────────────┴────────────┴────────┴─────────────┴─────────────┴─────────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_periodicity(\n",
    "    df,\n",
    "    periodicity_dict,\n",
    "    event2col: dict[str, str] = {\"onset\": \"prediction_onset\", \"wakeup\": \"prediction_wakeup\"},\n",
    "):\n",
    "    dfs = []\n",
    "    for series_id, series_df in df.group_by('series_id'):\n",
    "        for event, event_pred_col in event2col.items():\n",
    "            series_df.with_columns(\n",
    "                pl.Series(name=event_pred_col, values=series_df.get_column(event_pred_col).to_numpy() * (1 - periodicity_dict[series_id] ))\n",
    "            )\n",
    "        dfs.append(series_df)\n",
    "    return pl.concat(dfs)\n",
    "\n",
    "df = remove_periodicity(series_df, periodicity_dict)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "46217b92-3ff1-4528-872e-c6f268e87cf7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 後処理\n",
    "\"\"\"\n",
    "- 入力：モデルの1分毎の予測値\n",
    "\n",
    "- onset, wakeup ごとに処理を行う\n",
    "\n",
    "\"\"\"\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def post_process(\n",
    "    pred_df,\n",
    "    event_rate: int | float = 0.005,\n",
    "    height: float = 0.1,\n",
    "    event2col: dict[str, str] = {\"onset\": \"prediction_onset\", \"wakeup\": \"prediction_wakeup\"},\n",
    "    use_weight = False\n",
    "):\n",
    "    \"\"\"\n",
    "    1分ごとの予測値を用いてイベントを検出する\n",
    "    # TODO: 1段目のモデルを入れる場合は1分ごとの予測値をそのまま使わずに周辺の予測値をrollする方が良さそう？\n",
    "\n",
    "    用語\n",
    "    - 予測地点: 1段目 or 2段目のモデルによって得られた1分毎の予測位置\n",
    "    - 候補地点: event の候補となる 15秒 or 45秒始まりの30秒間隔の位置\n",
    "\n",
    "    Args:\n",
    "        pred_df (pl.DataFrame): series_id, step, event2colのvalue をカラムに持つ。stepが12の倍数以外の行は無視される。periodicityは削除済み想定\n",
    "        event_rate (int | float, optional): [0,1) の値であれば1分間に何回イベントが起こるか。intの場合はseries_idごとに同じイベント数を検出。 Defaults to 0.005.\n",
    "        height (float, optional): 候補地点の期待値がこの値を下回ったら終了。 Defaults to 0.1.\n",
    "    Returns:\n",
    "        event_df (pl.DataFrame): row_id, series_id, step, event, score をカラムに持つ。\n",
    "    \"\"\"\n",
    "    high_match_nums = [1, 3, 5, 8, 10, 13, 15, 20, 25, 30]\n",
    "    low_match_nums = [1, 3, 5, 7, 10, 12, 15, 20, 25, 30]\n",
    "    match_sums = [2, 6, 10, 15, 20, 25, 30, 40, 50, 60] if use_weight else np.ones(10)\n",
    "    total_num = sum(high_match_nums + low_match_nums)\n",
    "    result_events_records = []\n",
    "\n",
    "    # event ごとに処理\n",
    "    for event, event_pred_col in event2col.items():\n",
    "        \"\"\"\n",
    "        元の系列の予測地点(長さN): 0, 12, 24, 36, 48, 60, 72, 84, 96, 108, ..., (N-1)*12\n",
    "        15秒から30秒おきのevent候補地点(長さ2N): 3, 9, 15, 21, 27, 33, 39, 45, 51, 57, ..., (N-1)*12+3, (N-1)*12+9\n",
    "            - 15秒(3step)から1分おき(長さN): 3, 15, 27, 39, 51, 63, 75, 87, 99, 111, ..., (N-1)*12+3\n",
    "                - 左の個数 {12: 1, 36: 3, 60: 5, 90: *8*, 120: 10, 150: *13*, 180: 15, 240: 20, 300: 25, 360: 30} high_match_nums\n",
    "                - 右の個数 {12: 1, 36: 3, 60: 5, 90: *7*, 120: 10, 150: *12*, 180: 15, 240: 20, 300: 25, 360: 30} low_match_nums\n",
    "            - 45秒(9step)から1分おき(長さN): 9, 21, 33, 45, 57, 69, 81, 93, 105, 117, ..., (N-1)*12+9\n",
    "                - 左の個数 {12: 1, 36: 3, 60: 5, 90: *7*, 120: 10, 150: *12*, 180: 15, 240: 20, 300: 25, 360: 30} low_match_nums\n",
    "                - 右の個数 {12: 1, 36: 3, 60: 5, 90: *8*, 120: 10, 150: *13*, 180: 15, 240: 20, 300: 25, 360: 30} high_match_nums       \n",
    "        \"\"\"\n",
    "\n",
    "        # 12の倍数以外の行は無視して1分毎の予測値にする\n",
    "        minute_pred_df = pred_df.filter(pl.col(\"step\") % 12 == 0)\n",
    "        max_event_per_series = event_rate if isinstance(event_rate, int) else int(len(minute_pred_df) * event_rate)\n",
    "\n",
    "        # series_id, step でソート\n",
    "        minute_pred_df = minute_pred_df.sort([\"series_id\", \"step\"])\n",
    "\n",
    "        # 1. 期待値の計算\n",
    "        # 1.1 左側を計算 (同じindexの予測を含む左側を計算)\n",
    "        \"\"\"\n",
    "        以下をそれぞれ計算する\n",
    "        - 15秒(3step)から1分おき(長さN)での候補地点での期待値: stepは 3, 15, 27, 39, 51, 63, 75, 87, 99, 111, ..., (N-1)*12+3\n",
    "        - 45秒(9step)から1分おき(長さN)での候補地点での期待値: stepは 9, 21, 33, 45, 57, 69, 81, 93, 105, 117, ..., (N-1)*12+9\n",
    "        計算は左側の予測地点の数と、右側の予測地点の数\n",
    "        \"\"\"\n",
    "        minute_pred_df = minute_pred_df.with_columns(\n",
    "            pl.sum_horizontal(\n",
    "                [\n",
    "                    (\n",
    "                        pl.col(event_pred_col)\n",
    "                        .rolling_sum(window_size=window, center=False, min_periods=1)\n",
    "                        .over(\"series_id\") / match_sums[i]\n",
    "                    )\n",
    "                    for i, window in enumerate(high_match_nums)\n",
    "                ]\n",
    "            ).alias(f\"{event}_left_expectation_plus_3step\"),\n",
    "            pl.sum_horizontal(\n",
    "                [\n",
    "                    (\n",
    "                        pl.col(event_pred_col)\n",
    "                        .rolling_sum(window_size=window, center=False, min_periods=1)\n",
    "                        .over(\"series_id\") / match_sums[i]\n",
    "                    )\n",
    "                    for i, window in enumerate(low_match_nums)\n",
    "                ]\n",
    "            ).alias(f\"{event}_left_expectation_plus_9step\"),\n",
    "        )\n",
    "\n",
    "        # 1.2 右側を計算(同じindexの予測を含まない右側を計算。逆順にして一個ずらしrolling_sumを取る必要がある）\n",
    "        minute_pred_df = minute_pred_df.reverse()\n",
    "        minute_pred_df = minute_pred_df.with_columns(\n",
    "            pl.sum_horizontal(\n",
    "                [\n",
    "                    (\n",
    "                        pl.col(event_pred_col)\n",
    "                        .shift(1)\n",
    "                        .rolling_sum(window_size=window, center=False, min_periods=1)\n",
    "                        .over(\"series_id\")\n",
    "                        .fill_null(0) / match_sums[i]\n",
    "                    )\n",
    "                    for i, window in enumerate(low_match_nums)\n",
    "                ]\n",
    "            ).alias(f\"{event}_right_expectation_plus_3step\"),\n",
    "            pl.sum_horizontal(\n",
    "                [\n",
    "                    (\n",
    "                        pl.col(event_pred_col)\n",
    "                        .shift(1)\n",
    "                        .rolling_sum(window_size=window, center=False, min_periods=1)\n",
    "                        .over(\"series_id\")\n",
    "                        .fill_null(0) / match_sums[i]\n",
    "                    )\n",
    "                    for i, window in enumerate(high_match_nums)\n",
    "                ]\n",
    "            ).alias(f\"{event}_right_expectation_plus_9step\"),\n",
    "        )\n",
    "        minute_pred_df = minute_pred_df.reverse()\n",
    "\n",
    "        # 合計の期待値計算\n",
    "        minute_pred_df = minute_pred_df.with_columns(\n",
    "            (pl.col(f\"{event}_left_expectation_plus_3step\") + pl.col(f\"{event}_right_expectation_plus_3step\")).alias(\n",
    "                f\"{event}_expectation_sum_3step\"\n",
    "            ),\n",
    "            (pl.col(f\"{event}_left_expectation_plus_9step\") + pl.col(f\"{event}_right_expectation_plus_9step\")).alias(\n",
    "                f\"{event}_expectation_sum_9step\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # 3. 最大値の取得 & 期待値の割引\n",
    "        \"\"\"\n",
    "        各予測地点の power を管理する。powerは以下の11種類\n",
    "        0: その予測地点が影響を与える範囲は無い\n",
    "        1: その予測地点が影響を与える範囲は左右1つ(1min)\n",
    "        2: その予測地点が影響を与える範囲は左右3つ\n",
    "        ︙\n",
    "        10: 左右30(step 0~360)\n",
    "\n",
    "        event を作るたびに、eventからtolerance内にある予測地点のpowerを下げる。\n",
    "        その際に予測地点からtolerance内にある、eventがあったところも含めた候補地点の期待値を割り引く。\n",
    "        \"\"\"\n",
    "        for series_id, series_df in tqdm(\n",
    "            minute_pred_df.select(\n",
    "                [\"series_id\", event_pred_col, f\"{event}_expectation_sum_3step\", f\"{event}_expectation_sum_9step\"]\n",
    "            ).group_by(\"series_id\"),\n",
    "            desc=\"find peaks\",\n",
    "            leave=False,\n",
    "            total=len(minute_pred_df[\"series_id\"].unique()),\n",
    "        ):\n",
    "            preds = series_df[event_pred_col].to_numpy()\n",
    "            expectation_sum_3step = series_df[f\"{event}_expectation_sum_3step\"].to_numpy(writable=True)\n",
    "            expectation_sum_9step = series_df[f\"{event}_expectation_sum_9step\"].to_numpy(writable=True)\n",
    "            powers = np.ones(len(expectation_sum_3step), dtype=np.int32) * 10\n",
    "            for _ in range(max_event_per_series):  # 高い順に最大max_event_per_series個のeventを決定\n",
    "                # 3.1 最大値の取得\n",
    "                # 合計の期待値が最大のstepを取得\n",
    "                max_step3 = expectation_sum_3step.argmax()\n",
    "                max_score3 = expectation_sum_3step[max_step3]\n",
    "                max_step9 = expectation_sum_9step.argmax()\n",
    "                max_score9 = expectation_sum_9step[max_step9]\n",
    "                if max_score3 > max_score9:\n",
    "                    # print('max_score3')\n",
    "                    left_nums = [0] + high_match_nums\n",
    "                    right_nums = [0] + low_match_nums\n",
    "                    max_step_index = max_step3\n",
    "                    max_score = max_score3\n",
    "                    result_events_records.append(\n",
    "                        {\n",
    "                            \"series_id\": series_id,\n",
    "                            \"step\": max_step_index * 12 + 3,\n",
    "                            \"event\": event,\n",
    "                            \"score\": max_score,\n",
    "                        }\n",
    "                    )\n",
    "                else:\n",
    "                    # print('max_score9')\n",
    "                    left_nums = [0] + low_match_nums\n",
    "                    right_nums = [0] + high_match_nums\n",
    "                    max_step_index = max_step9\n",
    "                    max_score = max_score9\n",
    "                    result_events_records.append(\n",
    "                        {\n",
    "                            \"series_id\": series_id,\n",
    "                            \"step\": max_step_index * 12 + 9,\n",
    "                            \"event\": event,\n",
    "                            \"score\": max_score,\n",
    "                        }\n",
    "                    )\n",
    "                if max_score < height:  # 閾値以下なら終了\n",
    "                    break\n",
    "                # print(f\"max_step_index:{max_step_index}, max_score:{max_score}\")\n",
    "\n",
    "                # 3.2 期待値の割引\n",
    "                \"\"\"\n",
    "                各予測地点のpowerを修正するとともに、候補地点の期待値を割引く。\n",
    "                powerが pi まで小さくなることによってその予測値が影響を与える範囲が狭くなる。\n",
    "                つまり狭くなって範囲から抜けた expectation_sum の値が、その予測値の値*重みの分だけ小さくなる\n",
    "                \"\"\"\n",
    "                # 3.2.1 まずはpowerを修正するstepの候補を探す\n",
    "                target_step_powers = []  # (target_step, pred, base_power, power)のリスト\n",
    "                for pi in range(0, 10):\n",
    "                    # 左側\n",
    "                    for l_diff in range(left_nums[pi], left_nums[pi + 1]):\n",
    "                        target_step_index = max_step_index - l_diff\n",
    "                        if target_step_index < 0:\n",
    "                            break\n",
    "                        pred = preds[target_step_index]\n",
    "                        base_power = powers[target_step_index]\n",
    "                        if base_power > pi:  # power が小さくなる場合のみ修正\n",
    "                            target_step_powers.append((target_step_index, pred, base_power, pi))\n",
    "                    # 右側\n",
    "                    for r_diff in range(right_nums[pi] + 1, right_nums[pi + 1] + 1):  # 自分自身と同じindexは含めない\n",
    "                        target_step_index = max_step_index + r_diff\n",
    "                        if target_step_index >= len(powers):\n",
    "                            break\n",
    "                        pred = preds[target_step_index]\n",
    "                        base_power = powers[target_step_index]\n",
    "                        if base_power > pi:\n",
    "                            target_step_powers.append((target_step_index, pred, base_power, pi))\n",
    "                # print('target_step_powers', target_step_powers)\n",
    "\n",
    "                # 3.2.2 対象となる step の power を修正するとともに期待値を割り引く\n",
    "                \"\"\"\n",
    "                powerを下げるとともに、関連する期待値を修正する。\n",
    "                予測地点に遠いeventを検出した場合は、予測地点に近い候補地点であっても期待値はその分割り引かれる。\n",
    "                \n",
    "                3stepの修正をする時は target_stepから左側が low_match_nums, 右側が high_match_nums\n",
    "                9stepの修正をする時は target_stepから左側が high_match_nums, 右側が low_match_nums\n",
    "                だんだんと内側のみがのこるように修正する。\n",
    "\n",
    "                - powerが 10 → 8 になるケースは左右1~30個に影響を及ぼしていたものが、左右の1~20個に影響を及ぼすようになる。また、powerが2個減った分全体の期待値も割り引かれる\n",
    "                - powerが 10 → 5 になるケースは左右1~30個に影響を及ぼしていたものが、左右の1~12(13)個に影響を及ぼすようになる\n",
    "                - powerが 8 → 7 になるケースは左右1~20個に影響を及ぼしていたものが、左右の1~15個に影響を及ぼすようになる\n",
    "                \"\"\"\n",
    "                # print(expectation_sum_3step[max_step_index], expectation_sum_9step[max_step_index])\n",
    "                for si, pred, base_power, power in target_step_powers:\n",
    "                    # print(f\"si:{si}, pred:{pred}, base_power:{base_power}, power:{power}\")\n",
    "                    powers[si] = power\n",
    "                    # 中心ほど重みが強いので power ごとに処理\n",
    "                    for pi in range(\n",
    "                        base_power, power, -1\n",
    "                    ):  # base_powerからpowerに減らしていくことで予測値の外側から削る\n",
    "                        # 修正範囲を決定\n",
    "                        # 3stepの修正をする時は target_step_indexから左側が low_match_nums, 右側が high_match_nums\n",
    "                        left_nums = [0] + low_match_nums\n",
    "                        right_nums = [0] + high_match_nums\n",
    "                        ## left (left_diff_min, left_diff_max] を消す\n",
    "                        left_diff_max = left_nums[pi]\n",
    "                        # left_diff_min = left_nums[pi - 1]\n",
    "                        ## right (right_diff_min, right_diff_max] を消す\n",
    "                        right_diff_max = right_nums[pi]\n",
    "                        # right_diff_min = right_nums[(pi - 1)]\n",
    "                        expectation_sum_3step[si - left_diff_max : si + right_diff_max] -= pred / match_sums[pi-1]\n",
    "                        \"\"\"\n",
    "                        if ((si-left_diff_max <= max_step_index) and (max_step_index < si+right_diff_max)):\n",
    "                            print(f'3step pi:{pi}')\n",
    "                            print(f\"max_step_index:{max_step_index}, si:{si}, left_diff_max:{left_diff_max}, right_diff_max:{right_diff_max}\") \n",
    "                            print(\"[\", si-left_diff_max, si+right_diff_max, \")\")\n",
    "                            print(f\"power: {pi}→{pi-1}, pred:{pred}\")\n",
    "                            print()\n",
    "                        \"\"\"\n",
    "\n",
    "                        # 9step\n",
    "                        left_nums = [0] + high_match_nums\n",
    "                        right_nums = [0] + low_match_nums\n",
    "                        # [si-left_diff_max, si-left_diff_min)\n",
    "                        left_diff_max = left_nums[pi]\n",
    "                        # left_diff_min = left_nums[(pi - 1)]\n",
    "                        # [si+right_diff_min, si+right_diff_max)\n",
    "                        # right_diff_min = right_nums[(pi - 1)]\n",
    "                        right_diff_max = right_nums[pi]\n",
    "                        expectation_sum_9step[si - left_diff_max : si + right_diff_max] -= pred / match_sums[pi-1]\n",
    "                        \"\"\"\n",
    "                        if ((si-left_diff_max <= max_step_index) and (max_step_index < si+right_diff_max)):\n",
    "                            print(f'9step pi:{pi}')\n",
    "                            print(f\"max_step_index:{max_step_index}, si:{si}, left_diff_max:{left_diff_max}, right_diff_max:{right_diff_max}\") \n",
    "                            print(\"[\", si-left_diff_max, si+right_diff_max, \")\")\n",
    "                            print(f\"power: {pi}→{pi-1}, pred:{pred}\")\n",
    "                            print()\n",
    "                        \"\"\"\n",
    "\n",
    "                # print(expectation_sum_3step[max_step_index], expectation_sum_9step[max_step_index])\n",
    "\n",
    "    sub_df = pl.DataFrame(result_events_records).sort(by=[\"series_id\", \"step\"])\n",
    "    row_ids = pl.Series(name=\"row_id\", values=np.arange(len(sub_df)))\n",
    "    sub_df = sub_df.with_columns(row_ids).select([\"row_id\", \"series_id\", \"step\", \"event\", \"score\"])\n",
    "    return sub_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a7012c59-0e79-42be-b560-c3553ffd2d02",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>series_id</th><th>night</th><th>event</th><th>step</th><th>timestamp</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>i64</td><td>datetime[μs, UTC]</td></tr></thead><tbody><tr><td>&quot;99b829cbad2d&quot;</td><td>1</td><td>&quot;onset&quot;</td><td>3960</td><td>2017-10-01 01:30:00 UTC</td></tr><tr><td>&quot;99b829cbad2d&quot;</td><td>1</td><td>&quot;wakeup&quot;</td><td>10836</td><td>2017-10-01 11:03:00 UTC</td></tr><tr><td>&quot;99b829cbad2d&quot;</td><td>2</td><td>&quot;onset&quot;</td><td>20508</td><td>2017-10-02 00:29:00 UTC</td></tr><tr><td>&quot;99b829cbad2d&quot;</td><td>2</td><td>&quot;wakeup&quot;</td><td>27624</td><td>2017-10-02 10:22:00 UTC</td></tr><tr><td>&quot;99b829cbad2d&quot;</td><td>3</td><td>&quot;onset&quot;</td><td>37884</td><td>2017-10-03 00:37:00 UTC</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────────┬───────┬────────┬───────┬─────────────────────────┐\n",
       "│ series_id    ┆ night ┆ event  ┆ step  ┆ timestamp               │\n",
       "│ ---          ┆ ---   ┆ ---    ┆ ---   ┆ ---                     │\n",
       "│ str          ┆ i64   ┆ str    ┆ i64   ┆ datetime[μs, UTC]       │\n",
       "╞══════════════╪═══════╪════════╪═══════╪═════════════════════════╡\n",
       "│ 99b829cbad2d ┆ 1     ┆ onset  ┆ 3960  ┆ 2017-10-01 01:30:00 UTC │\n",
       "│ 99b829cbad2d ┆ 1     ┆ wakeup ┆ 10836 ┆ 2017-10-01 11:03:00 UTC │\n",
       "│ 99b829cbad2d ┆ 2     ┆ onset  ┆ 20508 ┆ 2017-10-02 00:29:00 UTC │\n",
       "│ 99b829cbad2d ┆ 2     ┆ wakeup ┆ 27624 ┆ 2017-10-02 10:22:00 UTC │\n",
       "│ 99b829cbad2d ┆ 3     ┆ onset  ┆ 37884 ┆ 2017-10-03 00:37:00 UTC │\n",
       "└──────────────┴───────┴────────┴───────┴─────────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "find peaks:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "find peaks:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>row_id</th><th>series_id</th><th>step</th><th>event</th><th>score</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>&quot;99b829cbad2d&quot;</td><td>2361</td><td>&quot;onset&quot;</td><td>0.011819</td></tr><tr><td>1</td><td>&quot;99b829cbad2d&quot;</td><td>2751</td><td>&quot;onset&quot;</td><td>0.012751</td></tr><tr><td>2</td><td>&quot;99b829cbad2d&quot;</td><td>2775</td><td>&quot;onset&quot;</td><td>0.04116</td></tr><tr><td>3</td><td>&quot;99b829cbad2d&quot;</td><td>2799</td><td>&quot;onset&quot;</td><td>0.102666</td></tr><tr><td>4</td><td>&quot;99b829cbad2d&quot;</td><td>2829</td><td>&quot;onset&quot;</td><td>0.568996</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌────────┬──────────────┬──────┬───────┬──────────┐\n",
       "│ row_id ┆ series_id    ┆ step ┆ event ┆ score    │\n",
       "│ ---    ┆ ---          ┆ ---  ┆ ---   ┆ ---      │\n",
       "│ i64    ┆ str          ┆ i64  ┆ str   ┆ f64      │\n",
       "╞════════╪══════════════╪══════╪═══════╪══════════╡\n",
       "│ 0      ┆ 99b829cbad2d ┆ 2361 ┆ onset ┆ 0.011819 │\n",
       "│ 1      ┆ 99b829cbad2d ┆ 2751 ┆ onset ┆ 0.012751 │\n",
       "│ 2      ┆ 99b829cbad2d ┆ 2775 ┆ onset ┆ 0.04116  │\n",
       "│ 3      ┆ 99b829cbad2d ┆ 2799 ┆ onset ┆ 0.102666 │\n",
       "│ 4      ┆ 99b829cbad2d ┆ 2829 ┆ onset ┆ 0.568996 │\n",
       "└────────┴──────────────┴──────┴───────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "319\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Matching detections to ground truth events:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8807229439958405\n",
      "\n",
      "find_peaks\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "find peaks:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>row_id</th><th>series_id</th><th>step</th><th>event</th><th>score</th></tr><tr><td>i64</td><td>str</td><td>u32</td><td>str</td><td>f32</td></tr></thead><tbody><tr><td>0</td><td>&quot;99b829cbad2d&quot;</td><td>2363</td><td>&quot;onset&quot;</td><td>0.001348</td></tr><tr><td>1</td><td>&quot;99b829cbad2d&quot;</td><td>2475</td><td>&quot;onset&quot;</td><td>0.00078</td></tr><tr><td>2</td><td>&quot;99b829cbad2d&quot;</td><td>2715</td><td>&quot;onset&quot;</td><td>0.00168</td></tr><tr><td>3</td><td>&quot;99b829cbad2d&quot;</td><td>2825</td><td>&quot;onset&quot;</td><td>0.118529</td></tr><tr><td>4</td><td>&quot;99b829cbad2d&quot;</td><td>2935</td><td>&quot;onset&quot;</td><td>0.00163</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌────────┬──────────────┬──────┬───────┬──────────┐\n",
       "│ row_id ┆ series_id    ┆ step ┆ event ┆ score    │\n",
       "│ ---    ┆ ---          ┆ ---  ┆ ---   ┆ ---      │\n",
       "│ i64    ┆ str          ┆ u32  ┆ str   ┆ f32      │\n",
       "╞════════╪══════════════╪══════╪═══════╪══════════╡\n",
       "│ 0      ┆ 99b829cbad2d ┆ 2363 ┆ onset ┆ 0.001348 │\n",
       "│ 1      ┆ 99b829cbad2d ┆ 2475 ┆ onset ┆ 0.00078  │\n",
       "│ 2      ┆ 99b829cbad2d ┆ 2715 ┆ onset ┆ 0.00168  │\n",
       "│ 3      ┆ 99b829cbad2d ┆ 2825 ┆ onset ┆ 0.118529 │\n",
       "│ 4      ┆ 99b829cbad2d ┆ 2935 ┆ onset ┆ 0.00163  │\n",
       "└────────┴──────────────┴──────┴───────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Matching detections to ground truth events:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8987719560133354\n"
     ]
    }
   ],
   "source": [
    "# 一旦 series1つでのスコア計算テスト\n",
    "\"\"\"\n",
    "\"efbfc4526d58\"\n",
    "\"6ca4f4fca6a2\"\n",
    "\"a88088855de5\"\n",
    "\"3be2f86c3e45\"\n",
    "\"e30cb792a2bc\"\n",
    "\"18b61dd5aae8\"\n",
    "\"e6ddbaaf0639\"\n",
    "\"9a340507e36a\"\n",
    "\"\"\"\n",
    "# テストのために一つのseriesに絞る\n",
    "series_id = \"99b829cbad2d\" #\"99b829cbad2d\"\n",
    "series_df = pred_all_df.filter(pl.col('series_id')==series_id)\n",
    "series_event_df = event_df.filter(pl.col('series_id')==series_id)\n",
    "\n",
    "\"\"\"\n",
    "series_df=series_df.with_columns(\n",
    "    pl.lit(1.0, dtype=pl.Float32).alias('prediction_onset')\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "display(series_event_df.head())\n",
    "\n",
    "print('new')\n",
    "sub_df = post_process(\n",
    "    remove_periodicity(series_df, periodicity_dict),\n",
    "    event_rate=500, #0.01, # 0.005: 0.8242786502556662\n",
    "    height = 0.01,\n",
    "    use_weight=True\n",
    ") \n",
    "display(sub_df.head())\n",
    "print(len(sub_df))\n",
    "        \n",
    "score = event_detection_ap(\n",
    "    series_event_df.to_pandas(),\n",
    "    sub_df.to_pandas(),\n",
    ")\n",
    "\n",
    "print(score)\n",
    "\n",
    "print()\n",
    "print('find_peaks')\n",
    "sub_df = make_submission(\n",
    "    series_df,\n",
    "    periodicity_dict= periodicity_dict,\n",
    "    height = 0.001,\n",
    "    distance = 110,\n",
    "    daily_score_offset = 1.0,\n",
    "    day_norm=True\n",
    ") \n",
    "display(sub_df.head())\n",
    "print(len(sub_df))\n",
    "        \n",
    "score = event_detection_ap(\n",
    "    series_event_df.to_pandas(),\n",
    "    sub_df.to_pandas(),\n",
    ")\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "c8cb0559-4a7a-4599-bbb0-8f45c57ebe40",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "find peaks:   0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "find peaks:   0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>row_id</th><th>series_id</th><th>step</th><th>event</th><th>score</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>&quot;038441c925bb&quot;</td><td>4923</td><td>&quot;onset&quot;</td><td>0.148425</td></tr><tr><td>1</td><td>&quot;038441c925bb&quot;</td><td>4947</td><td>&quot;onset&quot;</td><td>0.442321</td></tr><tr><td>2</td><td>&quot;038441c925bb&quot;</td><td>4971</td><td>&quot;onset&quot;</td><td>1.083233</td></tr><tr><td>3</td><td>&quot;038441c925bb&quot;</td><td>4995</td><td>&quot;onset&quot;</td><td>25.857357</td></tr><tr><td>4</td><td>&quot;038441c925bb&quot;</td><td>5025</td><td>&quot;onset&quot;</td><td>0.732165</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌────────┬──────────────┬──────┬───────┬───────────┐\n",
       "│ row_id ┆ series_id    ┆ step ┆ event ┆ score     │\n",
       "│ ---    ┆ ---          ┆ ---  ┆ ---   ┆ ---       │\n",
       "│ i64    ┆ str          ┆ i64  ┆ str   ┆ f64       │\n",
       "╞════════╪══════════════╪══════╪═══════╪═══════════╡\n",
       "│ 0      ┆ 038441c925bb ┆ 4923 ┆ onset ┆ 0.148425  │\n",
       "│ 1      ┆ 038441c925bb ┆ 4947 ┆ onset ┆ 0.442321  │\n",
       "│ 2      ┆ 038441c925bb ┆ 4971 ┆ onset ┆ 1.083233  │\n",
       "│ 3      ┆ 038441c925bb ┆ 4995 ┆ onset ┆ 25.857357 │\n",
       "│ 4      ┆ 038441c925bb ┆ 5025 ┆ onset ┆ 0.732165  │\n",
       "└────────┴──────────────┴──────┴───────┴───────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[25.6GB(+0.7GB):116.3sec] post_process \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "228167\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Matching detections to ground truth events:   0%|          | 0/538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7922797626687601\n"
     ]
    }
   ],
   "source": [
    "tmp = remove_periodicity(pred_all_df, periodicity_dict)\n",
    "\n",
    "with trace(\"post_process\"):\n",
    "    sub_df = post_process(\n",
    "        tmp,\n",
    "        event_per_minute = 0.005,\n",
    "        height = 0.1,\n",
    "    ) \n",
    "    display(sub_df.head())\n",
    "print(len(sub_df))\n",
    "\n",
    "score = event_detection_ap(\n",
    "    event_df.to_pandas(),\n",
    "    sub_df.to_pandas(),\n",
    ")\n",
    "\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c93101f9-e865-41d7-9dcc-c49cf2ef3ca9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "find peaks:   0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46843\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Matching detections to ground truth events:   0%|          | 0/538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8133512719452747\n"
     ]
    }
   ],
   "source": [
    "sub_df1 = make_submission(\n",
    "    pred_all_df,\n",
    "    periodicity_dict= periodicity_dict,\n",
    "    height = 0.001,\n",
    "    distance = 107,\n",
    "    daily_score_offset = 1.0,\n",
    "    day_norm=True\n",
    ") \n",
    "print(len(sub_df1))\n",
    "\n",
    "score = event_detection_ap(\n",
    "    event_df.to_pandas(),\n",
    "    sub_df1.to_pandas(),\n",
    ")\n",
    "print(score) #0.78818291 0.756548\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838a267c-57af-44bb-84f4-9cbe85439aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
