{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3188b7d-842c-4a7d-ba5d-8a73a82e5b02",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys, os\n",
    "sys.path.append(os.pardir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1d6496d-1b3f-489c-a6ca-d98b4981a69a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import os\n",
    "from hydra import initialize, compose\n",
    "\n",
    "with initialize(config_path=\"../run/conf\", version_base=None):\n",
    "    cfg = compose(\"cv_train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f66bfc1-93f9-4f92-8443-51719882cede",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "from src.utils.metrics import event_detection_ap\n",
    "from src.utils.periodicity import get_periodicity_dict\n",
    "from src.utils.common import trace\n",
    "from src.utils.post_process import make_submission\n",
    "\n",
    "periodicity_dict = get_periodicity_dict(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ada909ba-e9c9-48fb-a83b-74a215106722",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "event_df = pl.read_csv(Path(cfg.dir.data_dir) / \"train_events.csv\").drop_nulls()\n",
    "event_df = event_df.with_columns(\n",
    "    pl.col(\"timestamp\").str.to_datetime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b85dbc5-7cc5-4f61-8401-0aeca752b31a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred_df = (\n",
    "    pl.read_parquet(\"./pred_onset.parquet\")\n",
    "    .rename({\"label_pred\": \"stacking_prediction_onset\"})\n",
    "    .drop(\"label\")\n",
    "    .join(\n",
    "        pl.read_parquet(\"./pred_wakeup.parquet\")\n",
    "        .rename({\"label_pred\": \"stacking_prediction_wakeup\"})\n",
    "        .drop(\"label\"),\n",
    "        on=[\"series_id\", \"step\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    ")\n",
    "pred_df = pred_df.with_columns(\n",
    "    ((pl.col(\"step\") - pl.col(\"step\").shift(1)) != 12)\n",
    "    .cast(int)\n",
    "    .cumsum()\n",
    "    .over(\"series_id\")\n",
    "    .fill_null(0)\n",
    "    .alias(\"chunk_id\")\n",
    ").with_columns(pl.col('step').cast(pl.UInt32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b9b3f9a-ad57-4bd0-afc2-947b1aee705e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>series_id</th><th>step</th><th>stacking_prediction_onset</th><th>stacking_prediction_wakeup</th><th>chunk_id</th></tr><tr><td>str</td><td>u32</td><td>f64</td><td>f64</td><td>i64</td></tr></thead><tbody><tr><td>&quot;038441c925bb&quot;</td><td>0</td><td>0.000008</td><td>0.00001</td><td>0</td></tr><tr><td>&quot;038441c925bb&quot;</td><td>12</td><td>0.000008</td><td>0.000008</td><td>0</td></tr><tr><td>&quot;038441c925bb&quot;</td><td>24</td><td>0.000007</td><td>0.000031</td><td>0</td></tr><tr><td>&quot;038441c925bb&quot;</td><td>36</td><td>0.000009</td><td>0.000019</td><td>0</td></tr><tr><td>&quot;038441c925bb&quot;</td><td>48</td><td>0.000006</td><td>0.000007</td><td>0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────────┬──────┬───────────────────────────┬────────────────────────────┬──────────┐\n",
       "│ series_id    ┆ step ┆ stacking_prediction_onset ┆ stacking_prediction_wakeup ┆ chunk_id │\n",
       "│ ---          ┆ ---  ┆ ---                       ┆ ---                        ┆ ---      │\n",
       "│ str          ┆ u32  ┆ f64                       ┆ f64                        ┆ i64      │\n",
       "╞══════════════╪══════╪═══════════════════════════╪════════════════════════════╪══════════╡\n",
       "│ 038441c925bb ┆ 0    ┆ 0.000008                  ┆ 0.00001                    ┆ 0        │\n",
       "│ 038441c925bb ┆ 12   ┆ 0.000008                  ┆ 0.000008                   ┆ 0        │\n",
       "│ 038441c925bb ┆ 24   ┆ 0.000007                  ┆ 0.000031                   ┆ 0        │\n",
       "│ 038441c925bb ┆ 36   ┆ 0.000009                  ┆ 0.000019                   ┆ 0        │\n",
       "│ 038441c925bb ┆ 48   ┆ 0.000006                  ┆ 0.000007                   ┆ 0        │\n",
       "└──────────────┴──────┴───────────────────────────┴────────────────────────────┴──────────┘"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8cfa6cef-de90-4d3f-9dd6-34ff6746f0ee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>series_id</th><th>step</th><th>timestamp</th><th>anglez</th><th>enmo</th></tr><tr><td>str</td><td>u32</td><td>datetime[μs, UTC]</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>&quot;038441c925bb&quot;</td><td>0</td><td>2018-08-14 19:30:00 UTC</td><td>2.6367</td><td>0.0217</td></tr><tr><td>&quot;038441c925bb&quot;</td><td>12</td><td>2018-08-14 19:31:00 UTC</td><td>2.4129</td><td>0.0218</td></tr><tr><td>&quot;038441c925bb&quot;</td><td>24</td><td>2018-08-14 19:32:00 UTC</td><td>30.002501</td><td>0.0082</td></tr><tr><td>&quot;038441c925bb&quot;</td><td>36</td><td>2018-08-14 19:33:00 UTC</td><td>-79.968803</td><td>0.0136</td></tr><tr><td>&quot;038441c925bb&quot;</td><td>48</td><td>2018-08-14 19:34:00 UTC</td><td>-80.014297</td><td>0.0141</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────────┬──────┬─────────────────────────┬────────────┬────────┐\n",
       "│ series_id    ┆ step ┆ timestamp               ┆ anglez     ┆ enmo   │\n",
       "│ ---          ┆ ---  ┆ ---                     ┆ ---        ┆ ---    │\n",
       "│ str          ┆ u32  ┆ datetime[μs, UTC]       ┆ f32        ┆ f32    │\n",
       "╞══════════════╪══════╪═════════════════════════╪════════════╪════════╡\n",
       "│ 038441c925bb ┆ 0    ┆ 2018-08-14 19:30:00 UTC ┆ 2.6367     ┆ 0.0217 │\n",
       "│ 038441c925bb ┆ 12   ┆ 2018-08-14 19:31:00 UTC ┆ 2.4129     ┆ 0.0218 │\n",
       "│ 038441c925bb ┆ 24   ┆ 2018-08-14 19:32:00 UTC ┆ 30.002501  ┆ 0.0082 │\n",
       "│ 038441c925bb ┆ 36   ┆ 2018-08-14 19:33:00 UTC ┆ -79.968803 ┆ 0.0136 │\n",
       "│ 038441c925bb ┆ 48   ┆ 2018-08-14 19:34:00 UTC ┆ -80.014297 ┆ 0.0141 │\n",
       "└──────────────┴──────┴─────────────────────────┴────────────┴────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pl.read_parquet(Path(cfg.dir.data_dir) / \"train_series.parquet\")\n",
    "train_df = train_df.with_columns(\n",
    "            pl.col(\"timestamp\").str.to_datetime(\"%Y-%m-%dT%H:%M:%S%z\")\n",
    "        ).filter(pl.col('step')%12==0)\n",
    "pred_df = pred_df.join(train_df, on=['series_id', 'step'], how='left')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d56ef2bf-efea-45f7-b274-a1f12b7586e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>series_id</th><th>step</th><th>stacking_prediction_onset</th><th>stacking_prediction_wakeup</th><th>chunk_id</th><th>timestamp</th><th>anglez</th><th>enmo</th></tr><tr><td>str</td><td>u32</td><td>f64</td><td>f64</td><td>i64</td><td>datetime[μs, UTC]</td><td>f32</td><td>f32</td></tr></thead><tbody><tr><td>&quot;038441c925bb&quot;</td><td>0</td><td>0.000008</td><td>0.00001</td><td>0</td><td>2018-08-14 19:30:00 UTC</td><td>2.6367</td><td>0.0217</td></tr><tr><td>&quot;038441c925bb&quot;</td><td>12</td><td>0.000008</td><td>0.000008</td><td>0</td><td>2018-08-14 19:31:00 UTC</td><td>2.4129</td><td>0.0218</td></tr><tr><td>&quot;038441c925bb&quot;</td><td>24</td><td>0.000007</td><td>0.000031</td><td>0</td><td>2018-08-14 19:32:00 UTC</td><td>30.002501</td><td>0.0082</td></tr><tr><td>&quot;038441c925bb&quot;</td><td>36</td><td>0.000009</td><td>0.000019</td><td>0</td><td>2018-08-14 19:33:00 UTC</td><td>-79.968803</td><td>0.0136</td></tr><tr><td>&quot;038441c925bb&quot;</td><td>48</td><td>0.000006</td><td>0.000007</td><td>0</td><td>2018-08-14 19:34:00 UTC</td><td>-80.014297</td><td>0.0141</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 8)\n",
       "┌──────────────┬──────┬──────────────┬──────────────┬──────────┬─────────────┬────────────┬────────┐\n",
       "│ series_id    ┆ step ┆ stacking_pre ┆ stacking_pre ┆ chunk_id ┆ timestamp   ┆ anglez     ┆ enmo   │\n",
       "│ ---          ┆ ---  ┆ diction_onse ┆ diction_wake ┆ ---      ┆ ---         ┆ ---        ┆ ---    │\n",
       "│ str          ┆ u32  ┆ t            ┆ up           ┆ i64      ┆ datetime[μs ┆ f32        ┆ f32    │\n",
       "│              ┆      ┆ ---          ┆ ---          ┆          ┆ , UTC]      ┆            ┆        │\n",
       "│              ┆      ┆ f64          ┆ f64          ┆          ┆             ┆            ┆        │\n",
       "╞══════════════╪══════╪══════════════╪══════════════╪══════════╪═════════════╪════════════╪════════╡\n",
       "│ 038441c925bb ┆ 0    ┆ 0.000008     ┆ 0.00001      ┆ 0        ┆ 2018-08-14  ┆ 2.6367     ┆ 0.0217 │\n",
       "│              ┆      ┆              ┆              ┆          ┆ 19:30:00    ┆            ┆        │\n",
       "│              ┆      ┆              ┆              ┆          ┆ UTC         ┆            ┆        │\n",
       "│ 038441c925bb ┆ 12   ┆ 0.000008     ┆ 0.000008     ┆ 0        ┆ 2018-08-14  ┆ 2.4129     ┆ 0.0218 │\n",
       "│              ┆      ┆              ┆              ┆          ┆ 19:31:00    ┆            ┆        │\n",
       "│              ┆      ┆              ┆              ┆          ┆ UTC         ┆            ┆        │\n",
       "│ 038441c925bb ┆ 24   ┆ 0.000007     ┆ 0.000031     ┆ 0        ┆ 2018-08-14  ┆ 30.002501  ┆ 0.0082 │\n",
       "│              ┆      ┆              ┆              ┆          ┆ 19:32:00    ┆            ┆        │\n",
       "│              ┆      ┆              ┆              ┆          ┆ UTC         ┆            ┆        │\n",
       "│ 038441c925bb ┆ 36   ┆ 0.000009     ┆ 0.000019     ┆ 0        ┆ 2018-08-14  ┆ -79.968803 ┆ 0.0136 │\n",
       "│              ┆      ┆              ┆              ┆          ┆ 19:33:00    ┆            ┆        │\n",
       "│              ┆      ┆              ┆              ┆          ┆ UTC         ┆            ┆        │\n",
       "│ 038441c925bb ┆ 48   ┆ 0.000006     ┆ 0.000007     ┆ 0        ┆ 2018-08-14  ┆ -80.014297 ┆ 0.0141 │\n",
       "│              ┆      ┆              ┆              ┆          ┆ 19:34:00    ┆            ┆        │\n",
       "│              ┆      ┆              ┆              ┆          ┆ UTC         ┆            ┆        │\n",
       "└──────────────┴──────┴──────────────┴──────────────┴──────────┴─────────────┴────────────┴────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfd5a84-6f5d-448c-b0c4-ae4a3e995b16",
   "metadata": {},
   "source": [
    "## 日毎にnormalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ec1bee4c-33e3-4b5d-9532-73719e56133f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "        \n",
    "def post_process_from_2nd(\n",
    "    pred_df,\n",
    "    event_rate: int | float = 500,\n",
    "    height: float = 0.001,\n",
    "    event2col: dict[str, str] = {\"onset\": \"stacking_prediction_onset\", \"wakeup\": \"stacking_prediction_wakeup\"},\n",
    "    weight_rate: float | None = 1.2,\n",
    "    day_norm: bool = True,\n",
    "    daily_score_offset=0.15,\n",
    "):\n",
    "    \"\"\"\n",
    "    1分ごとの予測値を用いてイベントを検出する\n",
    "    # TODO: 1段目のモデルを入れる場合は1分ごとの予測値をそのまま使わずに周辺の予測値をrollする方が良さそう？\n",
    "\n",
    "    用語\n",
    "    - 予測地点: 2段目のモデルによって得られた1分毎の予測位置\n",
    "    - 候補地点: event の候補となる 15秒 or 45秒始まりの30秒間隔の位置\n",
    "\n",
    "    Args:\n",
    "        pred_df (pl.DataFrame): timestamp 込み\n",
    "        event_rate (int | float, optional): [0,1) の値であれば1分間に何回イベントが起こるか。intの場合はseries_idごとに同じイベント数を検出。 Defaults to 0.005.\n",
    "        height (float, optional): 候補地点の期待値がこの値を下回ったら終了。 Defaults to 0.1.\n",
    "        event2col (dict[str, str], optional): event名と予測値のカラム名の対応。 Defaults to {\"onset\": \"stacking_prediction_onset\", \"wakeup\": \"stacking_prediction_wakeup\"}.\n",
    "        weight_rate (float | None, optional): 遠くの予測値の期待値を割り引く際の重み。Noneの場合は重みを1とする。1/weight_rate 倍ずつ遠くの予測値の重みが小さくなっていく。 Defaults to None.\n",
    "        day_norm (bool, optional): 一日ごとに予測値を正規化するかどうか。 Defaults to False.\n",
    "        daily_score_offset (float, optional): 正規化の際のoffset。 Defaults to 1.0.\n",
    "    Returns:\n",
    "        event_df (pl.DataFrame): row_id, series_id, step, event, score をカラムに持つ。\n",
    "    \"\"\"\n",
    "    high_match_nums = [1, 3, 5, 8, 10, 13, 15, 20, 25, 30]\n",
    "    low_match_nums = [1, 3, 5, 7, 10, 12, 15, 20, 25, 30]\n",
    "    match_sums = [np.power(weight_rate, i) for i in range(10)] if weight_rate else np.ones(10)\n",
    "    # match_sums = [1.0+weight_rate*i for i in range(10)] if weight_rate else np.ones(10)\n",
    "    total_num = sum(high_match_nums + low_match_nums)\n",
    "    # total_num = sum(high_match_nums + low_match_nums)\n",
    "    result_events_records = []\n",
    "\n",
    "    # event ごとに処理\n",
    "    for event, event_pred_col in event2col.items():\n",
    "        \"\"\"\n",
    "        元の系列の予測地点(長さN): 0, 12, 24, 36, 48, 60, 72, 84, 96, 108, ..., (N-1)*12\n",
    "        15秒から30秒おきのevent候補地点(長さ2N): 3, 9, 15, 21, 27, 33, 39, 45, 51, 57, ..., (N-1)*12+3, (N-1)*12+9\n",
    "            - 15秒(3step)から1分おき(長さN): 3, 15, 27, 39, 51, 63, 75, 87, 99, 111, ..., (N-1)*12+3\n",
    "                - 左の個数 {12: 1, 36: 3, 60: 5, 90: *8*, 120: 10, 150: *13*, 180: 15, 240: 20, 300: 25, 360: 30} high_match_nums\n",
    "                - 右の個数 {12: 1, 36: 3, 60: 5, 90: *7*, 120: 10, 150: *12*, 180: 15, 240: 20, 300: 25, 360: 30} low_match_nums\n",
    "            - 45秒(9step)から1分おき(長さN): 9, 21, 33, 45, 57, 69, 81, 93, 105, 117, ..., (N-1)*12+9\n",
    "                - 左の個数 {12: 1, 36: 3, 60: 5, 90: *7*, 120: 10, 150: *12*, 180: 15, 240: 20, 300: 25, 360: 30} low_match_nums\n",
    "                - 右の個数 {12: 1, 36: 3, 60: 5, 90: *8*, 120: 10, 150: *13*, 180: 15, 240: 20, 300: 25, 360: 30} high_match_nums       \n",
    "        \"\"\"\n",
    "\n",
    "        # series内でのindexを振り、chunk内での最大と最小を計算\n",
    "        minute_pred_df = pred_df\n",
    "\n",
    "        if day_norm:\n",
    "            minute_pred_df = minute_pred_df.with_columns(\n",
    "                pl.col(\"timestamp\").dt.offset_by(\"2h\").dt.date().alias(\"date\")\n",
    "            ).with_columns(\n",
    "                pl.col(event_pred_col)\n",
    "                / (pl.col(event_pred_col).sum().over([\"series_id\", \"date\"]) + daily_score_offset)\n",
    "            )\n",
    "\n",
    "        max_event_per_series = event_rate if isinstance(event_rate, int) else int(len(minute_pred_df) * event_rate)\n",
    "\n",
    "        # series_id, chunk_id, step でソート\n",
    "        minute_pred_df = minute_pred_df.sort([\"series_id\", \"chunk_id\", \"step\"])\n",
    "\n",
    "        # 1. 期待値の計算\n",
    "        # 1.1 左側を計算 (同じindexの予測を含む左側を計算)\n",
    "        \"\"\"\n",
    "        以下をそれぞれ計算する\n",
    "        - 15秒(3step)から1分おき(長さN)での候補地点での期待値: stepは 3, 15, 27, 39, 51, 63, 75, 87, 99, 111, ..., (N-1)*12+3\n",
    "        - 45秒(9step)から1分おき(長さN)での候補地点での期待値: stepは 9, 21, 33, 45, 57, 69, 81, 93, 105, 117, ..., (N-1)*12+9\n",
    "        計算は左側の予測地点の数と、右側の予測地点の数\n",
    "        \"\"\"\n",
    "        minute_pred_df = minute_pred_df.with_columns(\n",
    "            pl.sum_horizontal(\n",
    "                [\n",
    "                    (\n",
    "                        pl.col(event_pred_col)\n",
    "                        .rolling_sum(window_size=window, center=False, min_periods=1)\n",
    "                        .over([\"series_id\", \"chunk_id\"])\n",
    "                        / match_sums[i]\n",
    "                    )\n",
    "                    for i, window in enumerate(high_match_nums)\n",
    "                ]\n",
    "            ).alias(f\"{event}_left_expectation_plus_3step\"),\n",
    "            pl.sum_horizontal(\n",
    "                [\n",
    "                    (\n",
    "                        pl.col(event_pred_col)\n",
    "                        .rolling_sum(window_size=window, center=False, min_periods=1)\n",
    "                        .over([\"series_id\", \"chunk_id\"])\n",
    "                        / match_sums[i]\n",
    "                    )\n",
    "                    for i, window in enumerate(low_match_nums)\n",
    "                ]\n",
    "            ).alias(f\"{event}_left_expectation_plus_9step\"),\n",
    "        )\n",
    "\n",
    "        # 1.2 右側を計算(同じindexの予測を含まない右側を計算。逆順にして一個ずらしrolling_sumを取る必要がある）\n",
    "        minute_pred_df = minute_pred_df.reverse()\n",
    "        minute_pred_df = minute_pred_df.with_columns(\n",
    "            pl.sum_horizontal(\n",
    "                [\n",
    "                    (\n",
    "                        pl.col(event_pred_col)\n",
    "                        .shift(1)\n",
    "                        .rolling_sum(window_size=window, center=False, min_periods=1)\n",
    "                        .over([\"series_id\", \"chunk_id\"])\n",
    "                        .fill_null(0)\n",
    "                        / match_sums[i]\n",
    "                    )\n",
    "                    for i, window in enumerate(low_match_nums)\n",
    "                ]\n",
    "            ).alias(f\"{event}_right_expectation_plus_3step\"),\n",
    "            pl.sum_horizontal(\n",
    "                [\n",
    "                    (\n",
    "                        pl.col(event_pred_col)\n",
    "                        .shift(1)\n",
    "                        .rolling_sum(window_size=window, center=False, min_periods=1)\n",
    "                        .over([\"series_id\", \"chunk_id\"])\n",
    "                        .fill_null(0)\n",
    "                        / match_sums[i]\n",
    "                    )\n",
    "                    for i, window in enumerate(high_match_nums)\n",
    "                ]\n",
    "            ).alias(f\"{event}_right_expectation_plus_9step\"),\n",
    "        )\n",
    "        minute_pred_df = minute_pred_df.reverse()\n",
    "\n",
    "        # 合計の期待値計算\n",
    "        minute_pred_df = minute_pred_df.with_columns(\n",
    "            (pl.col(f\"{event}_left_expectation_plus_3step\") + pl.col(f\"{event}_right_expectation_plus_3step\")).alias(\n",
    "                f\"{event}_expectation_sum_3step\"\n",
    "            ),\n",
    "            (pl.col(f\"{event}_left_expectation_plus_9step\") + pl.col(f\"{event}_right_expectation_plus_9step\")).alias(\n",
    "                f\"{event}_expectation_sum_9step\"\n",
    "            ),\n",
    "        )\n",
    "\n",
    "        # print(display(minute_pred_df))\n",
    "\n",
    "        # 3. 最大値の取得 & 期待値の割引\n",
    "        \"\"\"\n",
    "        各予測地点の power を管理する。powerは以下の11種類\n",
    "        0: その予測地点が影響を与える範囲は無い\n",
    "        1: その予測地点が影響を与える範囲は左右1つ(1min)\n",
    "        2: その予測地点が影響を与える範囲は左右3つ\n",
    "        ︙\n",
    "        10: 左右30(step 0~360)\n",
    "\n",
    "        event を作るたびに、eventからtolerance内にある予測地点のpowerを下げる。\n",
    "        その際に予測地点からtolerance内にある、eventがあったところも含めた候補地点の期待値を割り引く。\n",
    "        \"\"\"\n",
    "        for series_id, series_df in tqdm(\n",
    "            minute_pred_df.select(\n",
    "                [\n",
    "                    \"series_id\",\n",
    "                    \"chunk_id\",\n",
    "                    \"step\",\n",
    "                    event_pred_col,\n",
    "                    f\"{event}_expectation_sum_3step\",\n",
    "                    f\"{event}_expectation_sum_9step\",\n",
    "                ]\n",
    "            ).group_by(\"series_id\"),\n",
    "            desc=\"find peaks\",\n",
    "            leave=False,\n",
    "            total=len(minute_pred_df[\"series_id\"].unique()),\n",
    "        ):\n",
    "            # chunkごとの id の最大最小を計算\n",
    "            series_df = series_df.with_row_count().with_columns(\n",
    "                pl.col(\"row_nr\").max().over([\"chunk_id\"]).alias(\"max_id_in_chunk\"),\n",
    "                pl.col(\"row_nr\").min().over([\"chunk_id\"]).alias(\"min_id_in_chunk\"),\n",
    "            )\n",
    "\n",
    "            preds = series_df[event_pred_col].to_numpy()\n",
    "            expectation_sum_3step = series_df[f\"{event}_expectation_sum_3step\"].to_numpy(writable=True)\n",
    "            expectation_sum_9step = series_df[f\"{event}_expectation_sum_9step\"].to_numpy(writable=True)\n",
    "            steps = series_df[f\"step\"].to_numpy(writable=True)\n",
    "            step_id_mins = series_df[\"min_id_in_chunk\"].to_numpy()\n",
    "            step_id_maxs = series_df[\"max_id_in_chunk\"].to_numpy() + 1\n",
    "            powers = np.ones(len(expectation_sum_3step), dtype=np.int32) * 10\n",
    "            for _ in range(max_event_per_series):  # 高い順に最大max_event_per_series個のeventを決定\n",
    "                # 3.1 最大値の取得\n",
    "                # 合計の期待値が最大のstepを取得\n",
    "                max_step3 = expectation_sum_3step.argmax()\n",
    "                max_score3 = expectation_sum_3step[max_step3]\n",
    "                max_step9 = expectation_sum_9step.argmax()\n",
    "                max_score9 = expectation_sum_9step[max_step9]\n",
    "                if max_score3 > max_score9:\n",
    "                    # print('max_score3')\n",
    "                    left_nums = [0] + high_match_nums\n",
    "                    right_nums = [0] + low_match_nums\n",
    "                    max_step_index = max_step3\n",
    "                    max_score = max_score3\n",
    "                    result_events_records.append(\n",
    "                        {\n",
    "                            \"series_id\": series_id,\n",
    "                            \"step\": steps[max_step_index] + 3,\n",
    "                            \"event\": event,\n",
    "                            \"score\": max_score,\n",
    "                        }\n",
    "                    )\n",
    "                else:\n",
    "                    # print('max_score9')\n",
    "                    left_nums = [0] + low_match_nums\n",
    "                    right_nums = [0] + high_match_nums\n",
    "                    max_step_index = max_step9\n",
    "                    max_score = max_score9\n",
    "                    result_events_records.append(\n",
    "                        {\n",
    "                            \"series_id\": series_id,\n",
    "                            \"step\": steps[max_step_index] + 9,\n",
    "                            \"event\": event,\n",
    "                            \"score\": max_score,\n",
    "                        }\n",
    "                    )\n",
    "                if max_score < height:  # 閾値以下なら終了\n",
    "                    break\n",
    "                # print(f\"max_step_index:{max_step_index}, max_score:{max_score}\")\n",
    "\n",
    "                # 3.2 期待値の割引\n",
    "                \"\"\"\n",
    "                各予測地点のpowerを修正するとともに、候補地点の期待値を割引く。\n",
    "                powerが pi まで小さくなることによってその予測値が影響を与える範囲が狭くなる。\n",
    "                つまり狭くなって範囲から抜けた expectation_sum の値が、その予測値の値*重みの分だけ小さくなる\n",
    "                \"\"\"\n",
    "                # 3.2.1 まずはpowerを修正するstepの候補を探す\n",
    "                target_step_powers = []  # (target_step, pred, base_power, power, step_min, step_max)のリスト\n",
    "                for pi in range(0, 10):\n",
    "                    # 左側\n",
    "                    for l_diff in range(left_nums[pi], left_nums[pi + 1]):\n",
    "                        target_step_index = max_step_index - l_diff\n",
    "                        if target_step_index < 0:\n",
    "                            break\n",
    "                        pred = preds[target_step_index]\n",
    "                        base_power = powers[target_step_index]\n",
    "                        if base_power > pi:  # power が小さくなる場合のみ修正\n",
    "                            target_step_powers.append(\n",
    "                                (\n",
    "                                    target_step_index,\n",
    "                                    pred,\n",
    "                                    base_power,\n",
    "                                    pi,\n",
    "                                    step_id_mins[target_step_index],\n",
    "                                    step_id_maxs[target_step_index],\n",
    "                                )\n",
    "                            )\n",
    "                    # 右側\n",
    "                    for r_diff in range(right_nums[pi] + 1, right_nums[pi + 1] + 1): # 自分自身と同じindexは含めない\n",
    "                        target_step_index = max_step_index + r_diff\n",
    "                        if target_step_index >= len(powers):\n",
    "                            break\n",
    "                        pred = preds[target_step_index]\n",
    "                        base_power = powers[target_step_index]\n",
    "                        if base_power > pi:\n",
    "                            target_step_powers.append(\n",
    "                                (\n",
    "                                    target_step_index,\n",
    "                                    pred,\n",
    "                                    base_power,\n",
    "                                    pi,\n",
    "                                    step_id_mins[target_step_index],\n",
    "                                    step_id_maxs[target_step_index],\n",
    "                                )\n",
    "                            )\n",
    "                # print('target_step_powers', target_step_powers)\n",
    "\n",
    "                # 3.2.2 対象となる step の power を修正するとともに期待値を割り引く\n",
    "                \"\"\"\n",
    "                予測地点のpowerを下げるとともに、関連する候補地点の期待値を修正する。\n",
    "                検出したeventから遠い予測地点の場合は、予測地点に近い候補地点であっても期待値はその分割り引かれる。\n",
    "                3stepの修正をする時は target_stepから左側が low_match_nums, 右側が high_match_nums\n",
    "                9stepの修正をする時は target_stepから左側が high_match_nums, 右側が low_match_nums\n",
    "                だんだんと内側のみがのこるように修正する。\n",
    "\n",
    "                - powerが 10 → 8 になるケースは左右1~30個に影響を及ぼしていたものが、左右の1~20個に影響を及ぼすようになる。また、powerが2個減った分全体の期待値も割り引かれる\n",
    "                - powerが 10 → 5 になるケースは左右1~30個に影響を及ぼしていたものが、左右の1~12(13)個に影響を及ぼすようになる\n",
    "                - powerが 8 → 7 になるケースは左右1~20個に影響を及ぼしていたものが、左右の1~15個に影響を及ぼすようになる\n",
    "                \"\"\"\n",
    "                # print(expectation_sum_3step[max_step_index], expectation_sum_9step[max_step_index])\n",
    "                for si, pred, base_power, power, step_min, step_max in target_step_powers:\n",
    "                    # print(f\"si:{si}, pred:{pred}, base_power:{base_power}, power:{power}\")\n",
    "                    powers[si] = power\n",
    "                    # 中心ほど重みが強いので power ごとに処理\n",
    "                    for pi in range(\n",
    "                        base_power, power, -1\n",
    "                    ):  # base_powerからpowerに減らしていくことで予測値の外側から削る\n",
    "                        # 3step\n",
    "                        left_nums = [0] + low_match_nums\n",
    "                        right_nums = [0] + high_match_nums\n",
    "                        left_diff_max = left_nums[pi]\n",
    "                        right_diff_max = right_nums[pi]\n",
    "                        expectation_sum_3step[\n",
    "                            max(si - left_diff_max, step_min) : min(si + right_diff_max, step_max)\n",
    "                        ] -= pred / match_sums[pi - 1]\n",
    "                        \"\"\"\n",
    "                        if ((si-left_diff_max <= max_step_index) and (max_step_index < si+right_diff_max)):\n",
    "                            print(f'3step pi:{pi}')\n",
    "                            print(f\"max_step_index:{max_step_index}, si:{si}, left_diff_max:{left_diff_max}, right_diff_max:{right_diff_max}\") \n",
    "                            print(\"[\", si-left_diff_max, si+right_diff_max, \")\")\n",
    "                            print(f\"power: {pi}→{pi-1}, pred:{pred}\")\n",
    "                            print()\n",
    "                        \"\"\"\n",
    "                        # 9step\n",
    "                        left_nums = [0] + high_match_nums\n",
    "                        right_nums = [0] + low_match_nums\n",
    "                        left_diff_max = left_nums[pi]\n",
    "                        right_diff_max = right_nums[pi]\n",
    "                        expectation_sum_9step[\n",
    "                            max(si - left_diff_max, step_min) : min(si + right_diff_max, step_max)\n",
    "                        ] -= pred / match_sums[pi - 1]\n",
    "                        \"\"\"\n",
    "                        if ((si-left_diff_max <= max_step_index) and (max_step_index < si+right_diff_max)):\n",
    "                            print(f'9step pi:{pi}')\n",
    "                            print(f\"max_step_index:{max_step_index}, si:{si}, left_diff_max:{left_diff_max}, right_diff_max:{right_diff_max}\") \n",
    "                            print(\"[\", si-left_diff_max, si+right_diff_max, \")\")\n",
    "                            print(f\"power: {pi}→{pi-1}, pred:{pred}\")\n",
    "                            print()\n",
    "                        \"\"\"\n",
    "\n",
    "                # print(expectation_sum_3step[max_step_index], expectation_sum_9step[max_step_index])\n",
    "\n",
    "    if len(result_events_records) == 0:  # 一つも予測がない場合はdummyを入れる\n",
    "        result_events_records.append(\n",
    "            {\n",
    "                \"series_id\": series_id,\n",
    "                \"step\": 0,\n",
    "                \"event\": \"onset\",\n",
    "                \"score\": 0,\n",
    "            }\n",
    "        )\n",
    "    sub_df = pl.DataFrame(result_events_records).sort(by=[\"series_id\", \"step\"])\n",
    "    row_ids = pl.Series(name=\"row_id\", values=np.arange(len(sub_df)))\n",
    "    sub_df = sub_df.with_columns(row_ids).select([\"row_id\", \"series_id\", \"step\", \"event\", \"score\"])\n",
    "    return sub_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "04e816c1-4e44-4ac9-a8b2-f7deb0ee41f6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>series_id</th><th>night</th><th>event</th><th>step</th><th>timestamp</th></tr><tr><td>str</td><td>i64</td><td>str</td><td>i64</td><td>datetime[μs, UTC]</td></tr></thead><tbody><tr><td>&quot;99b829cbad2d&quot;</td><td>1</td><td>&quot;onset&quot;</td><td>3960</td><td>2017-10-01 01:30:00 UTC</td></tr><tr><td>&quot;99b829cbad2d&quot;</td><td>1</td><td>&quot;wakeup&quot;</td><td>10836</td><td>2017-10-01 11:03:00 UTC</td></tr><tr><td>&quot;99b829cbad2d&quot;</td><td>2</td><td>&quot;onset&quot;</td><td>20508</td><td>2017-10-02 00:29:00 UTC</td></tr><tr><td>&quot;99b829cbad2d&quot;</td><td>2</td><td>&quot;wakeup&quot;</td><td>27624</td><td>2017-10-02 10:22:00 UTC</td></tr><tr><td>&quot;99b829cbad2d&quot;</td><td>3</td><td>&quot;onset&quot;</td><td>37884</td><td>2017-10-03 00:37:00 UTC</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌──────────────┬───────┬────────┬───────┬─────────────────────────┐\n",
       "│ series_id    ┆ night ┆ event  ┆ step  ┆ timestamp               │\n",
       "│ ---          ┆ ---   ┆ ---    ┆ ---   ┆ ---                     │\n",
       "│ str          ┆ i64   ┆ str    ┆ i64   ┆ datetime[μs, UTC]       │\n",
       "╞══════════════╪═══════╪════════╪═══════╪═════════════════════════╡\n",
       "│ 99b829cbad2d ┆ 1     ┆ onset  ┆ 3960  ┆ 2017-10-01 01:30:00 UTC │\n",
       "│ 99b829cbad2d ┆ 1     ┆ wakeup ┆ 10836 ┆ 2017-10-01 11:03:00 UTC │\n",
       "│ 99b829cbad2d ┆ 2     ┆ onset  ┆ 20508 ┆ 2017-10-02 00:29:00 UTC │\n",
       "│ 99b829cbad2d ┆ 2     ┆ wakeup ┆ 27624 ┆ 2017-10-02 10:22:00 UTC │\n",
       "│ 99b829cbad2d ┆ 3     ┆ onset  ┆ 37884 ┆ 2017-10-03 00:37:00 UTC │\n",
       "└──────────────┴───────┴────────┴───────┴─────────────────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "find peaks:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "find peaks:   0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Matching detections to ground truth events:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8613241915445758\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>row_id</th><th>series_id</th><th>step</th><th>event</th><th>score</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>&quot;99b829cbad2d&quot;</td><td>2187</td><td>&quot;onset&quot;</td><td>0.00265</td></tr><tr><td>1</td><td>&quot;99b829cbad2d&quot;</td><td>2259</td><td>&quot;onset&quot;</td><td>0.001266</td></tr><tr><td>2</td><td>&quot;99b829cbad2d&quot;</td><td>2331</td><td>&quot;onset&quot;</td><td>0.0044</td></tr><tr><td>3</td><td>&quot;99b829cbad2d&quot;</td><td>2373</td><td>&quot;onset&quot;</td><td>0.035393</td></tr><tr><td>4</td><td>&quot;99b829cbad2d&quot;</td><td>2445</td><td>&quot;onset&quot;</td><td>0.004901</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌────────┬──────────────┬──────┬───────┬──────────┐\n",
       "│ row_id ┆ series_id    ┆ step ┆ event ┆ score    │\n",
       "│ ---    ┆ ---          ┆ ---  ┆ ---   ┆ ---      │\n",
       "│ i64    ┆ str          ┆ i64  ┆ str   ┆ f64      │\n",
       "╞════════╪══════════════╪══════╪═══════╪══════════╡\n",
       "│ 0      ┆ 99b829cbad2d ┆ 2187 ┆ onset ┆ 0.00265  │\n",
       "│ 1      ┆ 99b829cbad2d ┆ 2259 ┆ onset ┆ 0.001266 │\n",
       "│ 2      ┆ 99b829cbad2d ┆ 2331 ┆ onset ┆ 0.0044   │\n",
       "│ 3      ┆ 99b829cbad2d ┆ 2373 ┆ onset ┆ 0.035393 │\n",
       "│ 4      ┆ 99b829cbad2d ┆ 2445 ┆ onset ┆ 0.004901 │\n",
       "└────────┴──────────────┴──────┴───────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "889\n"
     ]
    }
   ],
   "source": [
    "# 一旦 series1つでのスコア計算テスト\n",
    "\"\"\"\n",
    "\"efbfc4526d58\"\n",
    "\"6ca4f4fca6a2\"\n",
    "\"a88088855de5\"\n",
    "\"3be2f86c3e45\"\n",
    "\"e30cb792a2bc\"\n",
    "\"18b61dd5aae8\"\n",
    "\"e6ddbaaf0639\"\n",
    "\"9a340507e36a\"\n",
    "\"\"\"\n",
    "# テストのために一つのseriesに絞る\n",
    "series_id = \"99b829cbad2d\" #\"99b829cbad2d\"\n",
    "series_df = pred_df.filter(pl.col('series_id')==series_id)\n",
    "series_event_df = event_df.filter(pl.col('series_id')==series_id)\n",
    "\n",
    "\"\"\"\n",
    "series_df=series_df.with_columns(\n",
    "    pl.lit(1.0, dtype=pl.Float32).alias('prediction_onset')\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "display(series_event_df.head())\n",
    "\n",
    "\n",
    "sub_df = post_process_from_2nd(\n",
    "    series_df,\n",
    ") \n",
    "\n",
    "        \n",
    "score = event_detection_ap(\n",
    "    series_event_df.to_pandas(),\n",
    "    sub_df.to_pandas(),\n",
    ")\n",
    "\n",
    "print(score)\n",
    "\n",
    "display(sub_df.head())\n",
    "print(len(sub_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "807a1762-0855-41a2-ac70-bcdeb6ca0ace",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "find peaks:   0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "find peaks:   0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>row_id</th><th>series_id</th><th>step</th><th>event</th><th>score</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>&quot;038441c925bb&quot;</td><td>2973</td><td>&quot;onset&quot;</td><td>0.002648</td></tr><tr><td>1</td><td>&quot;038441c925bb&quot;</td><td>4887</td><td>&quot;onset&quot;</td><td>0.003186</td></tr><tr><td>2</td><td>&quot;038441c925bb&quot;</td><td>4917</td><td>&quot;onset&quot;</td><td>0.001027</td></tr><tr><td>3</td><td>&quot;038441c925bb&quot;</td><td>4935</td><td>&quot;onset&quot;</td><td>0.020838</td></tr><tr><td>4</td><td>&quot;038441c925bb&quot;</td><td>4959</td><td>&quot;onset&quot;</td><td>0.061235</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌────────┬──────────────┬──────┬───────┬──────────┐\n",
       "│ row_id ┆ series_id    ┆ step ┆ event ┆ score    │\n",
       "│ ---    ┆ ---          ┆ ---  ┆ ---   ┆ ---      │\n",
       "│ i64    ┆ str          ┆ i64  ┆ str   ┆ f64      │\n",
       "╞════════╪══════════════╪══════╪═══════╪══════════╡\n",
       "│ 0      ┆ 038441c925bb ┆ 2973 ┆ onset ┆ 0.002648 │\n",
       "│ 1      ┆ 038441c925bb ┆ 4887 ┆ onset ┆ 0.003186 │\n",
       "│ 2      ┆ 038441c925bb ┆ 4917 ┆ onset ┆ 0.001027 │\n",
       "│ 3      ┆ 038441c925bb ┆ 4935 ┆ onset ┆ 0.020838 │\n",
       "│ 4      ┆ 038441c925bb ┆ 4959 ┆ onset ┆ 0.061235 │\n",
       "└────────┴──────────────┴──────┴───────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "161394\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Matching detections to ground truth events:   0%|          | 0/538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8219856413408265\n"
     ]
    }
   ],
   "source": [
    "sub_df = post_process_from_2nd(\n",
    "    pred_df,\n",
    "    event_rate=500,\n",
    "    height = 0.001,\n",
    "    weight_rate=1.2,\n",
    "    day_norm=True,\n",
    "    daily_score_offset=2.0, #1.0: 0.8256263945865044\n",
    ") # 1: 0.8121145868635269\n",
    "\n",
    "\n",
    "display(sub_df.head())\n",
    "print(len(sub_df))\n",
    "        \n",
    "score = event_detection_ap(\n",
    "    event_df.to_pandas(),\n",
    "    sub_df.to_pandas(),\n",
    ")\n",
    "\n",
    "\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "8d7e745e-115c-4f03-9f0b-64ee0208a247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "find peaks:   0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "find peaks:   0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>row_id</th><th>series_id</th><th>step</th><th>event</th><th>score</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>&quot;038441c925bb&quot;</td><td>579</td><td>&quot;wakeup&quot;</td><td>0.00243</td></tr><tr><td>1</td><td>&quot;038441c925bb&quot;</td><td>2973</td><td>&quot;onset&quot;</td><td>0.003236</td></tr><tr><td>2</td><td>&quot;038441c925bb&quot;</td><td>4887</td><td>&quot;onset&quot;</td><td>0.003895</td></tr><tr><td>3</td><td>&quot;038441c925bb&quot;</td><td>4911</td><td>&quot;onset&quot;</td><td>0.001256</td></tr><tr><td>4</td><td>&quot;038441c925bb&quot;</td><td>4935</td><td>&quot;onset&quot;</td><td>0.025473</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌────────┬──────────────┬──────┬────────┬──────────┐\n",
       "│ row_id ┆ series_id    ┆ step ┆ event  ┆ score    │\n",
       "│ ---    ┆ ---          ┆ ---  ┆ ---    ┆ ---      │\n",
       "│ i64    ┆ str          ┆ i64  ┆ str    ┆ f64      │\n",
       "╞════════╪══════════════╪══════╪════════╪══════════╡\n",
       "│ 0      ┆ 038441c925bb ┆ 579  ┆ wakeup ┆ 0.00243  │\n",
       "│ 1      ┆ 038441c925bb ┆ 2973 ┆ onset  ┆ 0.003236 │\n",
       "│ 2      ┆ 038441c925bb ┆ 4887 ┆ onset  ┆ 0.003895 │\n",
       "│ 3      ┆ 038441c925bb ┆ 4911 ┆ onset  ┆ 0.001256 │\n",
       "│ 4      ┆ 038441c925bb ┆ 4935 ┆ onset  ┆ 0.025473 │\n",
       "└────────┴──────────────┴──────┴────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "174191\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Matching detections to ground truth events:   0%|          | 0/538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8235109357670576\n"
     ]
    }
   ],
   "source": [
    "sub_df = post_process_from_2nd(\n",
    "    pred_df,\n",
    "    event_rate=500,\n",
    "    height = 0.001,\n",
    "    weight_rate=1.2,\n",
    "    day_norm=True,\n",
    "    daily_score_offset=1.5, #1.0: 0.8256263945865044\n",
    ") # 1: 0.8121145868635269\n",
    "\n",
    "\n",
    "display(sub_df.head())\n",
    "print(len(sub_df))\n",
    "        \n",
    "score = event_detection_ap(\n",
    "    event_df.to_pandas(),\n",
    "    sub_df.to_pandas(),\n",
    ")\n",
    "\n",
    "\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "951c04c4-14b2-432d-b493-b5f3201e6e4f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "find peaks:   0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "find peaks:   0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>row_id</th><th>series_id</th><th>step</th><th>event</th><th>score</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>&quot;038441c925bb&quot;</td><td>579</td><td>&quot;wakeup&quot;</td><td>0.007278</td></tr><tr><td>1</td><td>&quot;038441c925bb&quot;</td><td>2973</td><td>&quot;onset&quot;</td><td>0.00583</td></tr><tr><td>2</td><td>&quot;038441c925bb&quot;</td><td>4767</td><td>&quot;onset&quot;</td><td>0.001775</td></tr><tr><td>3</td><td>&quot;038441c925bb&quot;</td><td>4887</td><td>&quot;onset&quot;</td><td>0.007017</td></tr><tr><td>4</td><td>&quot;038441c925bb&quot;</td><td>4917</td><td>&quot;onset&quot;</td><td>0.002262</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌────────┬──────────────┬──────┬────────┬──────────┐\n",
       "│ row_id ┆ series_id    ┆ step ┆ event  ┆ score    │\n",
       "│ ---    ┆ ---          ┆ ---  ┆ ---    ┆ ---      │\n",
       "│ i64    ┆ str          ┆ i64  ┆ str    ┆ f64      │\n",
       "╞════════╪══════════════╪══════╪════════╪══════════╡\n",
       "│ 0      ┆ 038441c925bb ┆ 579  ┆ wakeup ┆ 0.007278 │\n",
       "│ 1      ┆ 038441c925bb ┆ 2973 ┆ onset  ┆ 0.00583  │\n",
       "│ 2      ┆ 038441c925bb ┆ 4767 ┆ onset  ┆ 0.001775 │\n",
       "│ 3      ┆ 038441c925bb ┆ 4887 ┆ onset  ┆ 0.007017 │\n",
       "│ 4      ┆ 038441c925bb ┆ 4917 ┆ onset  ┆ 0.002262 │\n",
       "└────────┴──────────────┴──────┴────────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "212044\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Matching detections to ground truth events:   0%|          | 0/538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.828957898279507\n"
     ]
    }
   ],
   "source": [
    "sub_df = post_process_from_2nd(\n",
    "    pred_df,\n",
    "    event_rate=500,\n",
    "    height = 0.001,\n",
    "    weight_rate=1.2,\n",
    "    day_norm=True,\n",
    "    daily_score_offset=0.5, #1.0: 0.8256263945865044\n",
    ") # 1: 0.8121145868635269\n",
    "\n",
    "\n",
    "display(sub_df.head())\n",
    "print(len(sub_df))\n",
    "        \n",
    "score = event_detection_ap(\n",
    "    event_df.to_pandas(),\n",
    "    sub_df.to_pandas(),\n",
    ")\n",
    "\n",
    "\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6dddcee3-0519-4533-a66d-7a2ae30121ce",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.15\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "find peaks:   0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "find peaks:   0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Matching detections to ground truth events:   0%|          | 0/538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8315786548321488\n",
      "0.2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "find peaks:   0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "find peaks:   0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Matching detections to ground truth events:   0%|          | 0/538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8313458680010021\n"
     ]
    }
   ],
   "source": [
    "for offset in [0.15, 0.2]:\n",
    "    print(offset)\n",
    "    sub_df = post_process_from_2nd(\n",
    "        pred_df,\n",
    "        event_rate=500,\n",
    "        height = 0.001,\n",
    "        weight_rate=1.2,\n",
    "        day_norm=True,\n",
    "        daily_score_offset=offset,\n",
    "    )\n",
    "\n",
    "    score = event_detection_ap(\n",
    "        event_df.to_pandas(),\n",
    "        sub_df.to_pandas(),\n",
    "    )\n",
    "\n",
    "\n",
    "    print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "457992d5-34f3-4f03-b266-ed42ed470a9a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.13\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee3c1a71188e45ecb19efe9827a6600a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "find peaks:   0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for offset in [0.13, 0.17]:\n",
    "    print(offset)\n",
    "    sub_df = post_process_from_2nd(\n",
    "        pred_df,\n",
    "        event_rate=500,\n",
    "        height = 0.001,\n",
    "        weight_rate=1.2,\n",
    "        day_norm=True,\n",
    "        daily_score_offset=offset,\n",
    "    )\n",
    "\n",
    "    score = event_detection_ap(\n",
    "        event_df.to_pandas(),\n",
    "        sub_df.to_pandas(),\n",
    "    )\n",
    "\n",
    "\n",
    "    print(score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb530043-5f27-4aea-8788-7ff7499eedd8",
   "metadata": {},
   "source": [
    "## tolerance内でmeanを取る"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58754d34-3799-4b59-a419-26408cb36d7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "388aa9a8-9240-42bd-bd3f-5bd970ecac4b",
   "metadata": {},
   "source": [
    "## 重みの和の最低値を1としてnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef28c81d-55b9-42a1-a724-5d9869a672e8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import polars as pl\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "\n",
    "def post_process_from_2nd(\n",
    "    pred_df,\n",
    "    event_rate: int | float = 0.005,\n",
    "    height: float = 0.1,\n",
    "    event2col: dict[str, str] = {\"onset\": \"stacking_prediction_onset\", \"wakeup\": \"stacking_prediction_wakeup\"},\n",
    "    weight_rate: float | None = None,\n",
    "    day_norm: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    1分ごとの予測値を用いてイベントを検出する\n",
    "    # TODO: 1段目のモデルを入れる場合は1分ごとの予測値をそのまま使わずに周辺の予測値をrollする方が良さそう？\n",
    "\n",
    "    用語\n",
    "    - 予測地点: 2段目のモデルによって得られた1分毎の予測位置\n",
    "    - 候補地点: event の候補となる 15秒 or 45秒始まりの30秒間隔の位置\n",
    "\n",
    "    Args:\n",
    "        pred_df (pl.DataFrame):\n",
    "        event_rate (int | float, optional): [0,1) の値であれば1分間に何回イベントが起こるか。intの場合はseries_idごとに同じイベント数を検出。 Defaults to 0.005.\n",
    "        height (float, optional): 候補地点の期待値がこの値を下回ったら終了。 Defaults to 0.1.\n",
    "        event2col (dict[str, str], optional): event名と予測値のカラム名の対応。 Defaults to {\"onset\": \"stacking_prediction_onset\", \"wakeup\": \"stacking_prediction_wakeup\"}.\n",
    "        weight_rate (float | None, optional): 遠くの予測値の期待値を割り引く際の重み。Noneの場合は重みを1とする。1/weight_rate 倍ずつ遠くの予測値の重みが小さくなっていく。 Defaults to None.\n",
    "        day_norm (bool, optional): 一日ごとに予測値を正規化するかどうか。 Defaults to False.\n",
    "        daily_score_offset (float, optional): 正規化の際のoffset。 Defaults to 1.0.\n",
    "    Returns:\n",
    "        event_df (pl.DataFrame): row_id, series_id, step, event, score をカラムに持つ。\n",
    "    \"\"\"\n",
    "    high_match_nums = [1, 3, 5, 8, 10, 13, 15, 20, 25, 30]\n",
    "    low_match_nums = [1, 3, 5, 7, 10, 12, 15, 20, 25, 30]\n",
    "    match_sums = [np.power(weight_rate, i) for i in range(10)] if weight_rate else np.ones(10)\n",
    "    #match_sums = [1.0+weight_rate*i for i in range(10)] if weight_rate else np.ones(10)\n",
    "    total_num = sum(high_match_nums + low_match_nums)\n",
    "    # total_num = sum(high_match_nums + low_match_nums)\n",
    "    result_events_records = []\n",
    "    \n",
    "    # event ごとに処理\n",
    "    for event, event_pred_col in event2col.items():\n",
    "        \"\"\"\n",
    "        元の系列の予測地点(長さN): 0, 12, 24, 36, 48, 60, 72, 84, 96, 108, ..., (N-1)*12\n",
    "        15秒から30秒おきのevent候補地点(長さ2N): 3, 9, 15, 21, 27, 33, 39, 45, 51, 57, ..., (N-1)*12+3, (N-1)*12+9\n",
    "            - 15秒(3step)から1分おき(長さN): 3, 15, 27, 39, 51, 63, 75, 87, 99, 111, ..., (N-1)*12+3\n",
    "                - 左の個数 {12: 1, 36: 3, 60: 5, 90: *8*, 120: 10, 150: *13*, 180: 15, 240: 20, 300: 25, 360: 30} high_match_nums\n",
    "                - 右の個数 {12: 1, 36: 3, 60: 5, 90: *7*, 120: 10, 150: *12*, 180: 15, 240: 20, 300: 25, 360: 30} low_match_nums\n",
    "            - 45秒(9step)から1分おき(長さN): 9, 21, 33, 45, 57, 69, 81, 93, 105, 117, ..., (N-1)*12+9\n",
    "                - 左の個数 {12: 1, 36: 3, 60: 5, 90: *7*, 120: 10, 150: *12*, 180: 15, 240: 20, 300: 25, 360: 30} low_match_nums\n",
    "                - 右の個数 {12: 1, 36: 3, 60: 5, 90: *8*, 120: 10, 150: *13*, 180: 15, 240: 20, 300: 25, 360: 30} high_match_nums       \n",
    "        \"\"\"\n",
    "\n",
    "        # series内でのindexを振り、chunk内での最大と最小を計算\n",
    "        minute_pred_df = pred_df\n",
    "\n",
    "        if day_norm:\n",
    "            minute_pred_df = minute_pred_df.with_columns(\n",
    "                pl.col(\"timestamp\").dt.offset_by(\"2h\").dt.date().alias(\"date\")\n",
    "            ).with_columns(\n",
    "                pl.col(event_pred_col) / pl.max_horizontal(pl.col(event_pred_col).sum().over([\"series_id\", \"date\"]), pl.lit(1.0))\n",
    "            )\n",
    "\n",
    "\n",
    "        max_event_per_series = event_rate if isinstance(event_rate, int) else int(len(minute_pred_df) * event_rate)\n",
    "\n",
    "        # series_id, chunk_id, step でソート\n",
    "        minute_pred_df = minute_pred_df.sort([\"series_id\", 'chunk_id', \"step\"])\n",
    "\n",
    "        # 1. 期待値の計算\n",
    "        # 1.1 左側を計算 (同じindexの予測を含む左側を計算)\n",
    "        \"\"\"\n",
    "        以下をそれぞれ計算する\n",
    "        - 15秒(3step)から1分おき(長さN)での候補地点での期待値: stepは 3, 15, 27, 39, 51, 63, 75, 87, 99, 111, ..., (N-1)*12+3\n",
    "        - 45秒(9step)から1分おき(長さN)での候補地点での期待値: stepは 9, 21, 33, 45, 57, 69, 81, 93, 105, 117, ..., (N-1)*12+9\n",
    "        計算は左側の予測地点の数と、右側の予測地点の数\n",
    "        \"\"\"\n",
    "        minute_pred_df = minute_pred_df.with_columns(\n",
    "            pl.sum_horizontal(\n",
    "                [\n",
    "                    (\n",
    "                        pl.col(event_pred_col)\n",
    "                        .rolling_sum(window_size=window, center=False, min_periods=1)\n",
    "                        .over(['series_id', 'chunk_id'])/ match_sums[i]\n",
    "                    )\n",
    "                    for i, window in enumerate(high_match_nums)\n",
    "                ]\n",
    "            ).alias(f\"{event}_left_expectation_plus_3step\"),\n",
    "            pl.sum_horizontal(\n",
    "                [\n",
    "                    (\n",
    "                        pl.col(event_pred_col)\n",
    "                        .rolling_sum(window_size=window, center=False, min_periods=1)\n",
    "                        .over(['series_id', 'chunk_id'])/ match_sums[i]\n",
    "                    )\n",
    "                    for i, window in enumerate(low_match_nums)\n",
    "                ]\n",
    "            ).alias(f\"{event}_left_expectation_plus_9step\"),\n",
    "        )\n",
    "\n",
    "        # 1.2 右側を計算(同じindexの予測を含まない右側を計算。逆順にして一個ずらしrolling_sumを取る必要がある）\n",
    "        minute_pred_df = minute_pred_df.reverse()\n",
    "        minute_pred_df = minute_pred_df.with_columns(\n",
    "            pl.sum_horizontal(\n",
    "                [\n",
    "                    (\n",
    "                        pl.col(event_pred_col)\n",
    "                        .shift(1)\n",
    "                        .rolling_sum(window_size=window, center=False, min_periods=1)\n",
    "                        .over(['series_id', 'chunk_id'])\n",
    "                        .fill_null(0)/ match_sums[i]\n",
    "                    )\n",
    "                    for i, window in enumerate(low_match_nums)\n",
    "                ]\n",
    "            ).alias(f\"{event}_right_expectation_plus_3step\"),\n",
    "            pl.sum_horizontal(\n",
    "                [\n",
    "                    (\n",
    "                        pl.col(event_pred_col)\n",
    "                        .shift(1)\n",
    "                        .rolling_sum(window_size=window, center=False, min_periods=1)\n",
    "                        .over(['series_id', 'chunk_id'])\n",
    "                        .fill_null(0)/ match_sums[i]\n",
    "                    )\n",
    "                    for i, window in enumerate(high_match_nums)\n",
    "                ]\n",
    "            ).alias(f\"{event}_right_expectation_plus_9step\"),\n",
    "        )\n",
    "        minute_pred_df = minute_pred_df.reverse()\n",
    "\n",
    "        # 合計の期待値計算\n",
    "        minute_pred_df = minute_pred_df.with_columns(\n",
    "            (pl.col(f\"{event}_left_expectation_plus_3step\") + pl.col(f\"{event}_right_expectation_plus_3step\")).alias(\n",
    "                f\"{event}_expectation_sum_3step\"\n",
    "            ),\n",
    "            (pl.col(f\"{event}_left_expectation_plus_9step\") + pl.col(f\"{event}_right_expectation_plus_9step\")).alias(\n",
    "                f\"{event}_expectation_sum_9step\"\n",
    "            ),\n",
    "        )\n",
    "        \n",
    "        #print(display(minute_pred_df))\n",
    "\n",
    "        # 3. 最大値の取得 & 期待値の割引\n",
    "        \"\"\"\n",
    "        各予測地点の power を管理する。powerは以下の11種類\n",
    "        0: その予測地点が影響を与える範囲は無い\n",
    "        1: その予測地点が影響を与える範囲は左右1つ(1min)\n",
    "        2: その予測地点が影響を与える範囲は左右3つ\n",
    "        ︙\n",
    "        10: 左右30(step 0~360)\n",
    "\n",
    "        event を作るたびに、eventからtolerance内にある予測地点のpowerを下げる。\n",
    "        その際に予測地点からtolerance内にある、eventがあったところも含めた候補地点の期待値を割り引く。\n",
    "        \"\"\"\n",
    "        for series_id, series_df in tqdm(\n",
    "            minute_pred_df.select(\n",
    "                [\"series_id\", 'chunk_id', 'step', event_pred_col, f\"{event}_expectation_sum_3step\", f\"{event}_expectation_sum_9step\"]\n",
    "            ).group_by(\"series_id\"),\n",
    "            desc=\"find peaks\",\n",
    "            leave=False,\n",
    "            total=len(minute_pred_df[\"series_id\"].unique()),\n",
    "        ):\n",
    "            # chunkごとの id の最大最小を計算\n",
    "            series_df = series_df.with_row_count().with_columns(\n",
    "                        pl.col('row_nr').max().over(['chunk_id']).alias('max_id_in_chunk'),\n",
    "                        pl.col('row_nr').min().over(['chunk_id']).alias('min_id_in_chunk'),\n",
    "                    )\n",
    "\n",
    "            preds = series_df[event_pred_col].to_numpy()\n",
    "            expectation_sum_3step = series_df[f\"{event}_expectation_sum_3step\"].to_numpy(writable=True)\n",
    "            expectation_sum_9step = series_df[f\"{event}_expectation_sum_9step\"].to_numpy(writable=True)\n",
    "            steps = series_df[f\"step\"].to_numpy(writable=True)\n",
    "            step_id_mins = series_df[\"min_id_in_chunk\"].to_numpy()\n",
    "            step_id_maxs = series_df[\"max_id_in_chunk\"].to_numpy() +1\n",
    "            powers = np.ones(len(expectation_sum_3step), dtype=np.int32) * 10\n",
    "            for _ in range(max_event_per_series):  # 高い順に最大max_event_per_series個のeventを決定\n",
    "                # 3.1 最大値の取得\n",
    "                # 合計の期待値が最大のstepを取得\n",
    "                max_step3 = expectation_sum_3step.argmax()\n",
    "                max_score3 = expectation_sum_3step[max_step3]\n",
    "                max_step9 = expectation_sum_9step.argmax()\n",
    "                max_score9 = expectation_sum_9step[max_step9]\n",
    "                if max_score3 > max_score9:\n",
    "                    # print('max_score3')\n",
    "                    left_nums = [0] + high_match_nums\n",
    "                    right_nums = [0] + low_match_nums\n",
    "                    max_step_index = max_step3\n",
    "                    max_score = max_score3\n",
    "                    result_events_records.append(\n",
    "                        {\n",
    "                            \"series_id\": series_id,\n",
    "                            \"step\": steps[max_step_index] + 3,\n",
    "                            \"event\": event,\n",
    "                            \"score\": max_score,\n",
    "                        }\n",
    "                    )\n",
    "                else:\n",
    "                    # print('max_score9')\n",
    "                    left_nums = [0] + low_match_nums\n",
    "                    right_nums = [0] + high_match_nums\n",
    "                    max_step_index = max_step9\n",
    "                    max_score = max_score9\n",
    "                    result_events_records.append(\n",
    "                        {\n",
    "                            \"series_id\": series_id,\n",
    "                            \"step\": steps[max_step_index] + 9,\n",
    "                            \"event\": event,\n",
    "                            \"score\": max_score,\n",
    "                        }\n",
    "                    )\n",
    "                if max_score < height:  # 閾値以下なら終了\n",
    "                    break\n",
    "                # print(f\"max_step_index:{max_step_index}, max_score:{max_score}\")\n",
    "\n",
    "                # 3.2 期待値の割引\n",
    "                \"\"\"\n",
    "                各予測地点のpowerを修正するとともに、候補地点の期待値を割引く。\n",
    "                powerが pi まで小さくなることによってその予測値が影響を与える範囲が狭くなる。\n",
    "                つまり狭くなって範囲から抜けた expectation_sum の値が、その予測値の値*重みの分だけ小さくなる\n",
    "                \"\"\"\n",
    "                # 3.2.1 まずはpowerを修正するstepの候補を探す\n",
    "                target_step_powers = []  # (target_step, pred, base_power, power, step_min, step_max)のリスト\n",
    "                for pi in range(0, 10):\n",
    "                    # 左側\n",
    "                    for l_diff in range(left_nums[pi], left_nums[pi + 1]):\n",
    "                        target_step_index = max_step_index - l_diff\n",
    "                        if target_step_index < 0:\n",
    "                            break\n",
    "                        pred = preds[target_step_index]\n",
    "                        base_power = powers[target_step_index]\n",
    "                        if base_power > pi:  # power が小さくなる場合のみ修正\n",
    "                            target_step_powers.append((target_step_index, pred, base_power, pi, step_id_mins[target_step_index], step_id_maxs[target_step_index]))\n",
    "                    # 右側\n",
    "                    for r_diff in range(right_nums[pi] + 1, right_nums[pi + 1] + 1):  # 自分自身と同じindexは含めない\n",
    "                        target_step_index = max_step_index + r_diff\n",
    "                        if target_step_index >= len(powers):\n",
    "                            break\n",
    "                        pred = preds[target_step_index]\n",
    "                        base_power = powers[target_step_index]\n",
    "                        if base_power > pi:\n",
    "                            target_step_powers.append((target_step_index, pred, base_power, pi, step_id_mins[target_step_index], step_id_maxs[target_step_index]))\n",
    "                #print('target_step_powers', target_step_powers)\n",
    "\n",
    "                # 3.2.2 対象となる step の power を修正するとともに期待値を割り引く\n",
    "                \"\"\"\n",
    "                予測地点のpowerを下げるとともに、関連する候補地点の期待値を修正する。\n",
    "                検出したeventから遠い予測地点の場合は、予測地点に近い候補地点であっても期待値はその分割り引かれる。\n",
    "                3stepの修正をする時は target_stepから左側が low_match_nums, 右側が high_match_nums\n",
    "                9stepの修正をする時は target_stepから左側が high_match_nums, 右側が low_match_nums\n",
    "                だんだんと内側のみがのこるように修正する。\n",
    "\n",
    "                - powerが 10 → 8 になるケースは左右1~30個に影響を及ぼしていたものが、左右の1~20個に影響を及ぼすようになる。また、powerが2個減った分全体の期待値も割り引かれる\n",
    "                - powerが 10 → 5 になるケースは左右1~30個に影響を及ぼしていたものが、左右の1~12(13)個に影響を及ぼすようになる\n",
    "                - powerが 8 → 7 になるケースは左右1~20個に影響を及ぼしていたものが、左右の1~15個に影響を及ぼすようになる\n",
    "                \"\"\"\n",
    "                #print(expectation_sum_3step[max_step_index], expectation_sum_9step[max_step_index])\n",
    "                for si, pred, base_power, power, step_min, step_max in target_step_powers:\n",
    "                    # print(f\"si:{si}, pred:{pred}, base_power:{base_power}, power:{power}\")\n",
    "                    powers[si] = power\n",
    "                    # 中心ほど重みが強いので power ごとに処理\n",
    "                    for pi in range(\n",
    "                        base_power, power, -1\n",
    "                    ):  # base_powerからpowerに減らしていくことで予測値の外側から削る\n",
    "                        # 3step\n",
    "                        left_nums = [0] + low_match_nums\n",
    "                        right_nums = [0] + high_match_nums\n",
    "                        left_diff_max = left_nums[pi]\n",
    "                        right_diff_max = right_nums[pi]\n",
    "                        expectation_sum_3step[max(si - left_diff_max, step_min) : min(si + right_diff_max, step_max)] -= pred / match_sums[pi-1]\n",
    "                        \"\"\"\n",
    "                        if ((si-left_diff_max <= max_step_index) and (max_step_index < si+right_diff_max)):\n",
    "                            print(f'3step pi:{pi}')\n",
    "                            print(f\"max_step_index:{max_step_index}, si:{si}, left_diff_max:{left_diff_max}, right_diff_max:{right_diff_max}\") \n",
    "                            print(\"[\", si-left_diff_max, si+right_diff_max, \")\")\n",
    "                            print(f\"power: {pi}→{pi-1}, pred:{pred}\")\n",
    "                            print()\n",
    "                        \"\"\"\n",
    "                        # 9step\n",
    "                        left_nums = [0] + high_match_nums\n",
    "                        right_nums = [0] + low_match_nums\n",
    "                        left_diff_max = left_nums[pi]\n",
    "                        right_diff_max = right_nums[pi]\n",
    "                        expectation_sum_9step[max(si - left_diff_max, step_min) : min(si + right_diff_max, step_max)] -= pred / match_sums[pi-1]\n",
    "                        \"\"\"\n",
    "                        if ((si-left_diff_max <= max_step_index) and (max_step_index < si+right_diff_max)):\n",
    "                            print(f'9step pi:{pi}')\n",
    "                            print(f\"max_step_index:{max_step_index}, si:{si}, left_diff_max:{left_diff_max}, right_diff_max:{right_diff_max}\") \n",
    "                            print(\"[\", si-left_diff_max, si+right_diff_max, \")\")\n",
    "                            print(f\"power: {pi}→{pi-1}, pred:{pred}\")\n",
    "                            print()\n",
    "                        \"\"\"\n",
    "\n",
    "                #print(expectation_sum_3step[max_step_index], expectation_sum_9step[max_step_index])\n",
    "    \n",
    "    if len(result_events_records) == 0:  # 一つも予測がない場合はdummyを入れる\n",
    "        result_events_records.append(\n",
    "            {\n",
    "                \"series_id\": series_id,\n",
    "                \"step\": 0,\n",
    "                \"event\": \"onset\",\n",
    "                \"score\": 0,\n",
    "            }\n",
    "        )\n",
    "    sub_df = pl.DataFrame(result_events_records).sort(by=[\"series_id\", \"step\"])\n",
    "    row_ids = pl.Series(name=\"row_id\", values=np.arange(len(sub_df)))\n",
    "    sub_df = sub_df.with_columns(row_ids).select([\"row_id\", \"series_id\", \"step\", \"event\", \"score\"])\n",
    "    return sub_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5e819d4f-57f6-46a0-9b80-d95f45bdad85",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "find peaks:   0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "find peaks:   0%|          | 0/277 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr > th,\n",
       ".dataframe > tbody > tr > td {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 5)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>row_id</th><th>series_id</th><th>step</th><th>event</th><th>score</th></tr><tr><td>i64</td><td>str</td><td>i64</td><td>str</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>&quot;038441c925bb&quot;</td><td>2973</td><td>&quot;onset&quot;</td><td>0.007275</td></tr><tr><td>1</td><td>&quot;038441c925bb&quot;</td><td>4767</td><td>&quot;onset&quot;</td><td>0.002215</td></tr><tr><td>2</td><td>&quot;038441c925bb&quot;</td><td>4887</td><td>&quot;onset&quot;</td><td>0.008756</td></tr><tr><td>3</td><td>&quot;038441c925bb&quot;</td><td>4911</td><td>&quot;onset&quot;</td><td>0.002823</td></tr><tr><td>4</td><td>&quot;038441c925bb&quot;</td><td>4935</td><td>&quot;onset&quot;</td><td>0.05726</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 5)\n",
       "┌────────┬──────────────┬──────┬───────┬──────────┐\n",
       "│ row_id ┆ series_id    ┆ step ┆ event ┆ score    │\n",
       "│ ---    ┆ ---          ┆ ---  ┆ ---   ┆ ---      │\n",
       "│ i64    ┆ str          ┆ i64  ┆ str   ┆ f64      │\n",
       "╞════════╪══════════════╪══════╪═══════╪══════════╡\n",
       "│ 0      ┆ 038441c925bb ┆ 2973 ┆ onset ┆ 0.007275 │\n",
       "│ 1      ┆ 038441c925bb ┆ 4767 ┆ onset ┆ 0.002215 │\n",
       "│ 2      ┆ 038441c925bb ┆ 4887 ┆ onset ┆ 0.008756 │\n",
       "│ 3      ┆ 038441c925bb ┆ 4911 ┆ onset ┆ 0.002823 │\n",
       "│ 4      ┆ 038441c925bb ┆ 4935 ┆ onset ┆ 0.05726  │\n",
       "└────────┴──────────────┴──────┴───────┴──────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219463\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Matching detections to ground truth events:   0%|          | 0/538 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8233806899837075\n"
     ]
    }
   ],
   "source": [
    "sub_df = post_process_from_2nd(\n",
    "    pred_df,\n",
    "    event_rate=500,\n",
    "    height = 0.001,\n",
    "    weight_rate=1.2,\n",
    "    day_norm=True,\n",
    ") \n",
    "\n",
    "\n",
    "display(sub_df.head())\n",
    "print(len(sub_df))\n",
    "        \n",
    "score = event_detection_ap(\n",
    "    event_df.to_pandas(),\n",
    "    sub_df.to_pandas(),\n",
    ")\n",
    "\n",
    "\n",
    "print(score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b1a8d8-d94e-4a7c-a110-6b4d5d330bfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
